{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "who-wrote-this.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw6VsDhUun5n",
        "colab_type": "text"
      },
      "source": [
        "# Who wrote this : a framework for French novelist identification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vARA24RjBr3f",
        "colab_type": "code",
        "outputId": "96e95546-eb9d-4e3f-8edf-57f9934d3e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd 'drive/My Drive/who-wrote-this/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/who-wrote-this\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rR8SIQ_ks-E",
        "colab_type": "code",
        "outputId": "6219daf8-24f2-4e44-cabf-986a0a9e0d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# !pip install --upgrade gensim\n",
        "!pip install unidecode\n",
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.6.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.26)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.26 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.26)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.26->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.26->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liRJXYg6Cv2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "8fd172b5-2a32-4b2b-de34-993e21c86292"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "import unidecode\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "import gensim\n",
        "from gensim.models import Doc2Vec, FastText\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUk_HtdMolVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of available cores for parallel computing\n",
        "N_CORES = cpu_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPykVwoCzxbu",
        "colab_type": "text"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i0eCW7-DDDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import train data\n",
        "train_df = pd.read_csv('data/corpus_train.csv', sep='|')\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True) # Shuffle\n",
        "X_train = train_df['paragraph'].values\n",
        "y_labels_train = train_df['author'].values\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_labels_train)\n",
        "N_CLASSES = len(np.unique(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPnN3eBy3slZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import test data and build validation dataset\n",
        "test_df = pd.read_csv('data/corpus_test.csv', sep='|')\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True) # Shuffle\n",
        "X_val, X_test, y_val, y_test = train_test_split(test_df['paragraph'].values,\n",
        "                                                test_df['author'].values,\n",
        "                                                test_size=0.5, random_state=42)\n",
        "y_val = le.transform(y_val)\n",
        "y_test = le.transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk7Dfp3JKzTj",
        "colab_type": "code",
        "outputId": "5f9ecfa5-a186-4d03-de4d-8d96d33d7423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train_df.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraph</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alors, dans cette première rafale, Gervaise, r...</td>\n",
              "      <td>Zola</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>--Il est possible, d'ailleurs, que nous nous r...</td>\n",
              "      <td>Verne</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fumée âcre et étouffante où se traînaient, ave...</td>\n",
              "      <td>Hugo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-- Nous allons chez l'abbé Scarron, pour leque...</td>\n",
              "      <td>Dumas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Le lecteur trouve cette conversation longue; p...</td>\n",
              "      <td>Stendhal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           paragraph    author\n",
              "0  Alors, dans cette première rafale, Gervaise, r...      Zola\n",
              "1  --Il est possible, d'ailleurs, que nous nous r...     Verne\n",
              "2  Fumée âcre et étouffante où se traînaient, ave...      Hugo\n",
              "3  -- Nous allons chez l'abbé Scarron, pour leque...     Dumas\n",
              "4  Le lecteur trouve cette conversation longue; p...  Stendhal"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pc4i1aPKJqv",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSOiEE20z1o4",
        "colab_type": "text"
      },
      "source": [
        "### Baseline : TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOwk-ES44rEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ML pipeline : TF-IDF + SVM classifier\n",
        "\n",
        "tfidf_vecto = TfidfVectorizer()\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "\n",
        "tfidf_pipeline = Pipeline([\n",
        "                           ('tf-idf', tfidf_vecto),\n",
        "                           ('clf', clf)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KlP_Iw2oth4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keep sklearn preprocessing pipeline for later\n",
        "preprocessor = tfidf_vecto.build_analyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ML1EXEK2kA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing + training\n",
        "tfidf_pipeline = tfidf_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdyNC-ok3qxy",
        "colab_type": "code",
        "outputId": "93dc340a-e2c7-4372-a586-2bab74d45145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute predictions and validation score\n",
        "y_val_pred_tfidf = tfidf_pipeline.predict(X_val)\n",
        "tfidf_val_score = f1_score(y_val, y_val_pred_tfidf, average='micro')\n",
        "print('F1 score on validation set with TF-IDF :', \n",
        "      tfidf_val_score.round(2))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set with TF-IDF : 0.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g88tOQuBz792",
        "colab_type": "text"
      },
      "source": [
        "### FastText (averaging of pre-trained word vectors)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAYXl07XADFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Fasttext French word vectors\n",
        "fasttext = FastText.load_fasttext_format('models/fasttext.fr.300.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r151opCRr8B1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_wv_fasttext(text):\n",
        "    \"\"\"Compute average of FastText's word vectors for a given text.\"\"\"\n",
        "    if text:\n",
        "        tokens = preprocessor(text)\n",
        "        wv_mat = np.zeros((len(tokens), fasttext.vector_size))\n",
        "        for i, tok in enumerate(tokens):\n",
        "            try:\n",
        "                wv_mat[i] = fasttext.wv[tok]\n",
        "            except KeyError:\n",
        "                pass\n",
        "        text_vec = wv_mat.mean(axis=0)\n",
        "    else:\n",
        "        text_vec = np.zeros(fasttext.vector_size)\n",
        "    return text_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRfHhI-LuzPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_corpus_fasttext(corpus):\n",
        "    \"\"\"Parallelize preprocessing and document vectors computation.\"\"\"\n",
        "    with Pool(N_CORES) as p:\n",
        "        corpus_prepro = p.map(text_to_wv_fasttext, list(corpus))\n",
        "    return np.array(corpus_prepro)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV7aqaByn1B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextToWV(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Enable to use preprocessing function in a sklearn pipeline.\"\"\"\n",
        "    def __init__(self, preprocessor):\n",
        "        self.preprocessor = preprocessor\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return(self)\n",
        "\n",
        "    def transform(self, X):\n",
        "        return self.preprocessor(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sg3YBbgJ0ZPm",
        "colab": {}
      },
      "source": [
        "# Prediction pipeline\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "fasttext_pipeline = Pipeline([\n",
        "                              ('fasttext_average', TextToWV(preprocess_corpus_fasttext)),\n",
        "                              ('clf', clf)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTvo5xwMob3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing + training\n",
        "fasttext_pipeline = fasttext_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIVGLvOm0pY_",
        "colab_type": "code",
        "outputId": "bacc522c-3acb-4bf5-ba3c-573b8af4d501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute predictions and test score\n",
        "y_val_pred_fasttext = fasttext_pipeline.predict(X_val)\n",
        "val_score_fasttext = f1_score(y_val, y_val_pred_fasttext, average='micro')\n",
        "print('F1 score on validation set :',\n",
        "      val_score_fasttext.round(2))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set : 0.35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL0DTOLbvYq1",
        "colab_type": "text"
      },
      "source": [
        "### Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztQM6FneveCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_d2v_corpus(corpus, tokens_only=False):\n",
        "    \"\"\"Tokenize and build corpus as expected by Gensim Doc2Vec class.\"\"\"\n",
        "    corpus_tokenized = []\n",
        "    for i, text in enumerate(corpus):\n",
        "        tokens = preprocessor(text)\n",
        "        if tokens_only:\n",
        "            corpus_tokenized.append(tokens)\n",
        "        else:\n",
        "            corpus_tokenized.append(TaggedDocument(tokens, [i]))\n",
        "    return corpus_tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krsC1SYh5ACx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Format train and validation corpus as required by Doc2Vec\n",
        "corpus_train_d2v = build_d2v_corpus(X_train, tokens_only=False)\n",
        "corpus_val_d2v = build_d2v_corpus(X_val, tokens_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryhxTy1C5wwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Doc2Vec model\n",
        "model = Doc2Vec(vector_size=50, min_count=2, epochs=10, workers=N_CORES)\n",
        "model.build_vocab(corpus_train_d2v)\n",
        "model.train(corpus_train_d2v, total_examples=model.corpus_count, \n",
        "            epochs=model.epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pLoVbMK8_DI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute document vectors on train and validation sets\n",
        "X_train_d2v = np.array([model.infer_vector(doc.words) for doc in corpus_train_d2v])\n",
        "X_val_d2v = np.array([model.infer_vector(doc) for doc in corpus_val_d2v])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe3LTThCAICg",
        "colab_type": "code",
        "outputId": "15585eb1-4ce9-433c-8678-4b531c15a372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute predictions and validation score\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "clf.fit(X_train_d2v, y_train)\n",
        "y_val_pred_d2v = clf.predict(X_val_d2v)\n",
        "val_score_d2v = f1_score(y_val, y_val_pred_d2v, average='micro')\n",
        "print('F1 score on validation set :', \n",
        "      val_score_d2v.round(2))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set : 0.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUqdN5M90AQV",
        "colab_type": "text"
      },
      "source": [
        "### CamemBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6W9sKtFRXbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CorpusToTorchDataset(Dataset):\n",
        "    \"\"\"Convert corpus to tensors of token indices in CamemBERT vocabulary.\"\"\"\n",
        "    def __init__(self, corpus, labels, model_name, maxlen=100):\n",
        "        self.corpus = corpus\n",
        "        self.labels = labels\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.corpus)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # Select instance\n",
        "        sentence = self.corpus[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        # Preprocess data as required by BERT models\n",
        "        tokens = self.tokenizer.tokenize(sentence)\n",
        "        bos_token = self.tokenizer.cls_token\n",
        "        eos_token = self.tokenizer.sep_token\n",
        "        pad_token = self.tokenizer.pad_token\n",
        "        # Insert CLS and SEP tokens at beginning and end of sentence\n",
        "        tokens = [bos_token] + tokens + [eos_token]\n",
        "        if len(tokens) < self.maxlen:\n",
        "            # If sentence is shorter than maxlen, pad sentence using special \n",
        "            # padding token\n",
        "            tokens = tokens + [pad_token for _ in range(self.maxlen - len(tokens))]\n",
        "        else:\n",
        "            # Cut the sentence if it is longer than maxlen\n",
        "            tokens = tokens[:self.maxlen-1] + [eos_token]\n",
        "\n",
        "        # Convert tokens to tensor of indices in CamemBERT vocabulary\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
        "        # Get attention mask to distinguish padding tokens from actual tokens\n",
        "        pad_token_id = self.tokenizer.convert_tokens_to_ids(pad_token)\n",
        "        attn_mask = (tokens_ids_tensor != pad_token_id).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDnF51VmVtHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create instances of training and validation dataloaders\n",
        "\n",
        "BERT_MODEL_NAME = 'camembert-base'\n",
        "MAXLEN = 100\n",
        "BATCH_SIZE = 12\n",
        "\n",
        "train_set = CorpusToTorchDataset(X_train, y_train, model_name=BERT_MODEL_NAME, maxlen=100)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=N_CORES)\n",
        "\n",
        "val_set = CorpusToTorchDataset(X_val, y_val, model_name=BERT_MODEL_NAME, maxlen=100)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=N_CORES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ydN8F8gOUI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CamemBERTClassifier(nn.Module):\n",
        "    \"\"\"Perform fine-tuning and classification using CamemBERT.\"\"\"\n",
        "    def __init__(self, pretrained_model_name=BERT_MODEL_NAME):\n",
        "        super(CamemBERTClassifier, self).__init__()\n",
        "        # Load CamemBERT\n",
        "        self.encoder = AutoModel.from_pretrained(pretrained_model_name)\n",
        "        # Add an extra dense layer to perform classification\n",
        "        self.cls_layer = nn.Linear(self.encoder.pooler.dense.out_features, N_CLASSES)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        # Feed input to BERT model to obtain contextualized representations\n",
        "        cont_reps, _ = self.encoder(seq, attention_mask = attn_masks)\n",
        "        # Get representation of [CLS] head\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "        # Feed document representation to the classifying layer\n",
        "        logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4A_4QjGOUP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate CamemBERT classifier model\n",
        "camembert_clf = CamemBERTClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f14mz-vhsuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss and optimizer\n",
        "criterion = CrossEntropyLoss()\n",
        "opti = Adam(camembert_clf.parameters(), lr = 3e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZUQxW1biwti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, criterion, opti, train_loader, val_loader, max_eps=3, \n",
        "          gpu=True, print_every=100, validate_every=1):\n",
        "    \"\"\"Train a transformer model and compute loss on validation data.\"\"\"\n",
        "    if gpu:\n",
        "        model = model.to(\"cuda\")\n",
        "    # Unfreeze weights to allow fine tuning\n",
        "    model.train() \n",
        "\n",
        "    train_loss_total = 0\n",
        "    n_batch_train = 0\n",
        "    for ep in range(max_eps):\n",
        "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "            # Clear gradients (avoid accumulation)\n",
        "            opti.zero_grad()  \n",
        "            # Transfer tensors to GPU\n",
        "            if gpu:\n",
        "                seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "            # Compute logits\n",
        "            logits = model(seq, attn_masks)\n",
        "            # Compute batch loss\n",
        "            loss = criterion(logits, labels)\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            # Optimization step\n",
        "            opti.step()\n",
        "            # Accumulate train loss over batches\n",
        "            train_loss_total += loss.item()\n",
        "            n_batch_train += 1\n",
        "\n",
        "            # Compute average loss over the last `print_every` training batches\n",
        "            if print_every is not None and (it + 1) % print_every == 0:\n",
        "                print(f'Epoch {ep+1}, batch {it+1}. Average loss over last {print_every} training batches : {train_loss_total/n_batch_train}')\n",
        "                # Reinitialize accumulators\n",
        "                train_loss_total = 0\n",
        "                n_batch_train = 0\n",
        "\n",
        "        if validate_every is not None and ep % validate_every == 0:\n",
        "            # Evaluation on the validation set\n",
        "\n",
        "            predictions_val = []\n",
        "            true_labels_val = []\n",
        "            for it, (seq, attn_masks, labels) in enumerate(val_loader):\n",
        "                if gpu:\n",
        "                    seq, attn_masks = seq.cuda(), attn_masks.cuda()\n",
        "                # Compute logits without constructing the computing graph\n",
        "                # (only needed for backprop)\n",
        "                with torch.no_grad():\n",
        "                    logits_val = model(seq, attn_masks)\n",
        "                preds_batch = torch.argmax(logits_val, 1).cpu().numpy()\n",
        "                predictions_val.extend(preds_batch)\n",
        "                true_labels_val.extend(labels.numpy())\n",
        "\n",
        "            val_f1 = f1_score(true_labels_val, predictions_val, average='micro')\n",
        "            print('------------------------------------------------------------')\n",
        "            print(\"Epoch {} complete. F1 score on validation data : {}\".format(ep+1, val_f1))\n",
        "            print('------------------------------------------------------------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nfxNPWenHb-",
        "colab_type": "code",
        "outputId": "ba12aef4-bd13-40e2-c88d-52a0773fb3d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Enforce deterministic behavior to ensure reproducibility of the results\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "train(camembert_clf, criterion, opti, train_loader, val_loader,\n",
        "      max_eps=1, gpu=True, print_every=500, validate_every=1)\n",
        "\n",
        "# Grid search (only 1 epoch each time, systematic overtraining above that) :\n",
        "# lr = 5e-5 => val_f1 = 0.49\n",
        "# lr = 3e-5 => val_f1 = 0.52"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, batch 500. Average loss over last 500 training batches : 1.6164042003154755\n",
            "Epoch 1, batch 1000. Average loss over last 500 training batches : 1.0134558594226837\n",
            "Epoch 1, batch 1500. Average loss over last 500 training batches : 0.7353367038667202\n",
            "Epoch 1, batch 2000. Average loss over last 500 training batches : 0.611015151232481\n",
            "Epoch 1, batch 2500. Average loss over last 500 training batches : 0.5248016767948865\n",
            "Epoch 1, batch 3000. Average loss over last 500 training batches : 0.4910539143830538\n",
            "Epoch 1, batch 3500. Average loss over last 500 training batches : 0.4564877462014556\n",
            "------------------------------------------------------------\n",
            "Epoch 1 complete. F1 score on validation data : 0.5199483689274819\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFNaQyUBKf6B",
        "colab_type": "text"
      },
      "source": [
        "# Final evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3tvHk02Kg4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TFIDF\n",
        "\n",
        "y_test_pred_tfidf = tfidf_pipeline.predict(X_test)\n",
        "test_score_tfidf = f1_score(y_test, y_test_pred_tfidf, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lLVo45ILnqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FastText\n",
        "\n",
        "y_test_pred_fasttext = fasttext_pipeline.predict(X_test)\n",
        "test_score_fasttext = f1_score(y_test, y_test_pred_fasttext, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxG0wUKGQ7PM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# doc2vec\n",
        "\n",
        "corpus_test_d2v = build_d2v_corpus(X_test, tokens_only=True)\n",
        "X_test_d2v = np.array([model.infer_vector(doc) for doc in corpus_test_d2v])\n",
        "y_test_pred_d2v = clf.predict(X_test_d2v)\n",
        "test_score_d2v = f1_score(y_test, y_test_pred_d2v, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTCCjA3yR0o0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CamemBERT\n",
        "\n",
        "# Create instance of test dataloader\n",
        "test_set = CorpusToTorchDataset(X_test, y_test, model_name=BERT_MODEL_NAME, maxlen=100)\n",
        "test_loader = DataLoader(test_set, batch_size = 12, num_workers = N_CORES)\n",
        "\n",
        "def eval(model, test_loader, gpu=True):\n",
        "    \"\"\"Compute predictions of a trained transforme model on test data.\"\"\"\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    for it, (seq, attn_masks, labels) in enumerate(test_loader):\n",
        "        if gpu:\n",
        "            seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "        # Compute logits without constructing the computing graph\n",
        "        # (only needed for backprop)\n",
        "        with torch.no_grad():\n",
        "            logits = model(seq, attn_masks)\n",
        "        # Compute predictions from logits and store them as arrays\n",
        "        preds_batch = torch.argmax(logits, 1).cpu().numpy()\n",
        "        predictions.extend(preds_batch)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "y_test_pred_camembert = eval(camembert_clf, test_loader)\n",
        "test_score_camembert = f1_score(y_test, y_test_pred_camembert, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7Xu42gIhQd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "f7714a35-0e4c-410d-e5a0-c3aa6a8a9794"
      },
      "source": [
        "# Compare performances\n",
        "models = ['TF-IDF', 'FastText', 'Doc2Vec', 'CamemBERT']\n",
        "scores = [test_score_tfidf, test_score_fasttext, test_score_d2v, test_score_camembert]\n",
        "df_scores = pd.DataFrame(zip(models, scores), columns=['Model', 'F1 score'])\n",
        "df_scores.sort_values('F1 score', ascending=False)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>F1 score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TF-IDF</td>\n",
              "      <td>0.515898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CamemBERT</td>\n",
              "      <td>0.515312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>0.388948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FastText</td>\n",
              "      <td>0.350933</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Model  F1 score\n",
              "0     TF-IDF  0.515898\n",
              "3  CamemBERT  0.515312\n",
              "2    Doc2Vec  0.388948\n",
              "1   FastText  0.350933"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    }
  ]
}