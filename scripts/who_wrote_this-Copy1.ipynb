{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/meteve/NLP_project/blob/master/scripts/who_wrote_this.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sw6VsDhUun5n"
   },
   "source": [
    "# Who wrote this : a framework for French novelist identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "liRJXYg6Cv2u",
    "outputId": "b6dd62e8-4285-4764-a1fc-e70aadd1ac5d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import unidecode\n",
    "import urllib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPykVwoCzxbu"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3i0eCW7-DDDU"
   },
   "outputs": [],
   "source": [
    "# Import train data\n",
    "train_df = pd.read_csv('../data/corpus_train_features_NER.csv', index_col=0)\n",
    "X_train_ner = train_df['paragraph_ner'].values\n",
    "X_train = train_df['paragraph'].values\n",
    "y_labels_train = train_df['author'].values\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPnN3eBy3slZ"
   },
   "outputs": [],
   "source": [
    "# Import test data\n",
    "test_df = pd.read_csv('../data/corpus_test_NER.csv', index_col=0)\n",
    "X_test_ner = test_df['paragraph_ner'].values\n",
    "X_test = test_df['paragraph'].values\n",
    "y_labels_test = test_df['author'].values\n",
    "y_test = le.transform(y_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avg1FM3GQ4dw"
   },
   "outputs": [],
   "source": [
    "def import_stopwords():\n",
    "    \"\"\"Download and import French stopwords.\"\"\"\n",
    "    URL = 'https://raw.githubusercontent.com/stopwords-iso/stopwords-fr/master/stopwords-fr.txt'\n",
    "    response = urllib.request.urlopen(URL)\n",
    "    stopwords = response.read().decode('utf-8').splitlines()\n",
    "    stopwords = [unidecode.unidecode(x) for x in stopwords]\n",
    "    stopwords.append('quelqu') # Make stopwords consistent with tokenization\n",
    "    return stopwords\n",
    "\n",
    "# Import french stopwords\n",
    "#with open('models/stopwords-fr.txt') as f:\n",
    " #   stopwords = f.read().splitlines()\n",
    "stopwords = import_stopwords()\n",
    "stopwords = [unidecode.unidecode(x) for x in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bSOiEE20z1o4"
   },
   "source": [
    "## Baseline TF-IDF model with and without NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOwk-ES44rEC"
   },
   "outputs": [],
   "source": [
    "# ML pipeline : TF-IDF + SVM classifier\n",
    "\n",
    "tfidf_vecto = TfidfVectorizer()\n",
    "clf = LinearSVC()\n",
    "\n",
    "tfidf_pipeline = Pipeline([\n",
    "                           ('tf-idf', tfidf_vecto),\n",
    "                           ('SVC', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare train and test scores with and without NER procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on train set with TF-IDF : 0.972\n",
      "F1 score with NER procedure on train set with TF-IDF : 0.973\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions on train and train score\n",
    "y_train_pred = tfidf_pipeline.predict(X_train)\n",
    "tfidf_test_score = f1_score(y_train, y_train_pred, average='micro')\n",
    "\n",
    "y_train_pred_ner = tfidf_pipeline_ner.predict(X_train_ner)\n",
    "tfidf_test_score_ner = f1_score(y_train, y_train_pred_ner, average='micro')\n",
    "\n",
    "print('F1 score on train set with TF-IDF :', \n",
    "      tfidf_test_score.round(3))\n",
    "print('F1 score with NER procedure on train set with TF-IDF :', \n",
    "      tfidf_test_score_ner.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WdyNC-ok3qxy",
    "outputId": "bb0a47bc-7951-498d-ac05-6f18b023a34d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on test set with TF-IDF : 0.501\n",
      "F1 score with NER procedure on test set with TF-IDF : 0.487\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions and test score\n",
    "y_pred = tfidf_pipeline.predict(X_test)\n",
    "tfidf_test_score = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "y_pred_ner = tfidf_pipeline_ner.predict(X_test_ner)\n",
    "tfidf_test_score_ner = f1_score(y_test, y_pred_ner, average='micro')\n",
    "\n",
    "print('F1 score on test set with TF-IDF :', \n",
    "      tfidf_test_score.round(3))\n",
    "print('F1 score with NER procedure on test set with TF-IDF :', \n",
    "      tfidf_test_score_ner.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_matrix_df(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    conf_matrix = pd.DataFrame(conf_matrix, columns=list(le.classes_), index=list(le.classes_))\n",
    "    \n",
    "    row_percentages = []\n",
    "    for i in range(0,10):\n",
    "        perc = round(conf_matrix.iloc[i,i]/sum(conf_matrix.iloc[0:10,i]), 3)\n",
    "        row_percentages.append(perc)\n",
    "    \n",
    "    row_percentages = pd.DataFrame([row_percentages], columns=list(le.classes_))\n",
    "    \n",
    "    col_percentages = []\n",
    "    for i in range(0,10):\n",
    "        perc = round(conf_matrix.iloc[i,i]/sum(conf_matrix.iloc[i,0:10]), 3)\n",
    "        col_percentages.append(perc)\n",
    "        \n",
    "    \n",
    "    conf_matrix['recall'] = col_percentages\n",
    "    conf_matrix = conf_matrix.append(row_percentages)\n",
    "    \n",
    "    return(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_train = get_conf_matrix_df(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_test = get_conf_matrix_df(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balzac</th>\n",
       "      <th>Daudet</th>\n",
       "      <th>Dumas</th>\n",
       "      <th>Flaubert</th>\n",
       "      <th>Hugo</th>\n",
       "      <th>Maupassant</th>\n",
       "      <th>Stendhal</th>\n",
       "      <th>Verne</th>\n",
       "      <th>Vigny</th>\n",
       "      <th>Zola</th>\n",
       "      <th>col_percentages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Balzac</td>\n",
       "      <td>730.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>409.000</td>\n",
       "      <td>116.000</td>\n",
       "      <td>129.000</td>\n",
       "      <td>101.000</td>\n",
       "      <td>546.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>0.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Daudet</td>\n",
       "      <td>21.000</td>\n",
       "      <td>79.000</td>\n",
       "      <td>170.000</td>\n",
       "      <td>91.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>55.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>52.000</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Dumas</td>\n",
       "      <td>99.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>3458.000</td>\n",
       "      <td>108.000</td>\n",
       "      <td>313.000</td>\n",
       "      <td>152.000</td>\n",
       "      <td>230.000</td>\n",
       "      <td>84.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>48.000</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Flaubert</td>\n",
       "      <td>26.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>155.000</td>\n",
       "      <td>624.000</td>\n",
       "      <td>125.000</td>\n",
       "      <td>87.000</td>\n",
       "      <td>96.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>58.000</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hugo</td>\n",
       "      <td>40.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>688.000</td>\n",
       "      <td>120.000</td>\n",
       "      <td>1521.000</td>\n",
       "      <td>107.000</td>\n",
       "      <td>309.000</td>\n",
       "      <td>146.000</td>\n",
       "      <td>42.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>0.498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Maupassant</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>126.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>211.000</td>\n",
       "      <td>36.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>42.000</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Stendhal</td>\n",
       "      <td>27.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>208.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>897.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Verne</td>\n",
       "      <td>12.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>181.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>52.000</td>\n",
       "      <td>421.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vigny</td>\n",
       "      <td>18.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>159.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>73.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>63.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zola</td>\n",
       "      <td>54.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>346.000</td>\n",
       "      <td>118.000</td>\n",
       "      <td>386.000</td>\n",
       "      <td>173.000</td>\n",
       "      <td>147.000</td>\n",
       "      <td>166.000</td>\n",
       "      <td>57.000</td>\n",
       "      <td>508.000</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.611</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Balzac  Daudet     Dumas  Flaubert      Hugo  Maupassant  \\\n",
       "Balzac      730.000  29.000   409.000   116.000   129.000     101.000   \n",
       "Daudet       21.000  79.000   170.000    91.000    88.000      72.000   \n",
       "Dumas        99.000  43.000  3458.000   108.000   313.000     152.000   \n",
       "Flaubert     26.000   8.000   155.000   624.000   125.000      87.000   \n",
       "Hugo         40.000  47.000   688.000   120.000  1521.000     107.000   \n",
       "Maupassant   18.000  18.000   126.000    50.000    75.000     211.000   \n",
       "Stendhal     27.000   9.000   208.000    33.000    39.000      29.000   \n",
       "Verne        12.000   2.000   181.000    39.000    56.000      24.000   \n",
       "Vigny        18.000  75.000   159.000    17.000    73.000      28.000   \n",
       "Zola         54.000  56.000   346.000   118.000   386.000     173.000   \n",
       "0             0.699   0.216     0.586     0.474     0.542       0.214   \n",
       "\n",
       "            Stendhal    Verne   Vigny     Zola  col_percentages  \n",
       "Balzac       546.000   39.000  33.000   53.000            0.334  \n",
       "Daudet        55.000   70.000  17.000   52.000            0.110  \n",
       "Dumas        230.000   84.000  38.000   48.000            0.756  \n",
       "Flaubert      96.000   21.000  11.000   58.000            0.515  \n",
       "Hugo         309.000  146.000  42.000   32.000            0.498  \n",
       "Maupassant    36.000   33.000   9.000   42.000            0.341  \n",
       "Stendhal     897.000   22.000  21.000   13.000            0.691  \n",
       "Verne         52.000  421.000  16.000   12.000            0.517  \n",
       "Vigny         63.000   35.000  85.000   14.000            0.150  \n",
       "Zola         147.000  166.000  57.000  508.000            0.253  \n",
       "0              0.369    0.406   0.258    0.611              NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g88tOQuBz792"
   },
   "source": [
    "## FastText pre-trained embeddings + averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_KlP_Iw2oth4"
   },
   "outputs": [],
   "source": [
    "# Use sklearn preprocessing pipeline to ensure results comparability\n",
    "preprocessor = tfidf_vecto.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAYXl07XADFH"
   },
   "outputs": [],
   "source": [
    "# Import Fasttext French word vectors\n",
    "fasttext = FastText.load_fasttext_format('models/fasttext.fr.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r151opCRr8B1"
   },
   "outputs": [],
   "source": [
    "def text_to_wv_fasttext(text):\n",
    "    \"\"\"Compute average of FastText's word vectors for a given text.\"\"\"\n",
    "    if text:\n",
    "        tokens = preprocessor(text)\n",
    "        wv_mat = np.zeros((len(tokens), fasttext.vector_size))\n",
    "        for i, tok in enumerate(tokens):\n",
    "            try:\n",
    "                wv_mat[i] = fasttext.wv[tok]\n",
    "            except KeyError:\n",
    "                pass\n",
    "        text_vec = wv_mat.mean(axis=0)\n",
    "    else:\n",
    "        text_vec = np.zeros(fasttext.vector_size)\n",
    "    return text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRfHhI-LuzPm"
   },
   "outputs": [],
   "source": [
    "def preprocess_corpus_fasttext(corpus):\n",
    "    \"\"\"Parallelize preprocessing and document vectors computation.\"\"\"\n",
    "    with Pool(N_CORES) as p:\n",
    "        corpus_prepro = p.map(text_to_wv_fasttext, list(corpus))\n",
    "    return np.array(corpus_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZV7aqaByn1B3"
   },
   "outputs": [],
   "source": [
    "class TextToWV(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Enable to use preprocessing function in a sklearn pipeline.\"\"\"\n",
    "    def __init__(self, preprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return(self)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.preprocessor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sg3YBbgJ0ZPm"
   },
   "outputs": [],
   "source": [
    "fasttext_pipeline = Pipeline([\n",
    "                              ('fasttext_average', TextToWV(preprocess_corpus_fasttext)),\n",
    "                              ('SVC', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTvo5xwMob3g"
   },
   "outputs": [],
   "source": [
    "# Preprocessing + training\n",
    "fasttext_pipeline = fasttext_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zIVGLvOm0pY_",
    "outputId": "08e42ad8-6110-4d1e-98a2-886c4d17a634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on test set with pre-trained FastText + averaging : 0.37\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions and test score\n",
    "y_pred = fasttext_pipeline.predict(X_test)\n",
    "fasttext_test_score = f1_score(y_test, y_pred, average='micro')\n",
    "print('F1 score on test set with pre-trained FastText + averaging :',\n",
    "      fasttext_test_score.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUqdN5M90AQV"
   },
   "source": [
    "## CamemBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "1AzW5DKbqv2C",
    "outputId": "3c103263-ea8a-43ee-d0f4-0f59a78ac7f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file models/camembert.v0\n",
      "| dictionary: 32004 types\n"
     ]
    }
   ],
   "source": [
    "# Import Camembert model\n",
    "camembert = CamembertModel.from_pretrained('models/camembert.v0')\n",
    "camembert.eval()\n",
    "CAMEMBERT_WV_SIZE = camembert.extract_features(camembert.encode('test string')).shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t6JyQxjTjl0j",
    "outputId": "c2668615-44c9-41bd-dc9b-7245f4c05e20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2334"
      ]
     },
     "execution_count": 159,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [camembert.encode(x) for x in X_train[:100]]\n",
    "max([len(x) for x in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xc4J1jNLtLYM"
   },
   "outputs": [],
   "source": [
    "def text_to_wv_camembert(text):\n",
    "    \"\"\"Compute average of CamemBERT's word vectors for a given text.\"\"\"\n",
    "    if text:\n",
    "        sentences = text.split('.')\n",
    "        sentences = [s for s in sentences if s]\n",
    "        tokens_ind = camembert.encode(*sentences)\n",
    "        text_features = camembert.extract_features(tokens_ind)\n",
    "        text_vec = text_features.squeeze(0).detach().numpy().mean(axis=0)\n",
    "    else:\n",
    "        text_vec = np.zeros(CAMEMBERT_WV_SIZE)\n",
    "    return text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DFhXaAphzz0a"
   },
   "outputs": [],
   "source": [
    "def preprocess_corpus_camembert(corpus):\n",
    "    \"\"\"\"\"\"\n",
    "    corpus_prepro = []\n",
    "    for i, text in enumerate(corpus):\n",
    "        corpus_prepro.append(text_to_wv_camembert(text))\n",
    "        print(i)\n",
    "    return np.array(corpus_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T3dhGEp0ucLe"
   },
   "outputs": [],
   "source": [
    "camembert_pipeline = Pipeline([\n",
    "                              ('camembert_average', TextToWV(preprocess_corpus_camembert)),\n",
    "                              ('SVC', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "asoCS8K6vOOz",
    "outputId": "ea946a7e-7336-440f-e0f6-6f13f82a5330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-fdc44ffcafb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcamembert_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamembert_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \"\"\"\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d56f9c0b65bc>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-139-b1198c481327>\u001b[0m in \u001b[0;36mpreprocess_corpus_camembert\u001b[0;34m(corpus)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcorpus_prepro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mcorpus_prepro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_to_wv_camembert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_prepro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-d469bf51fd15>\u001b[0m in \u001b[0;36mtext_to_wv_camembert\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtokens_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamembert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtext_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamembert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtext_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fairseq/models/roberta/hub_interface.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, tokens, return_all_hiddens)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             raise ValueError('tokens exceeds maximum length: {} > {}'.format(\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             ))\n\u001b[1;32m     84\u001b[0m         features, extra = self.model(\n",
      "\u001b[0;31mValueError\u001b[0m: tokens exceeds maximum length: 1321 > 512"
     ]
    }
   ],
   "source": [
    "# Preprocessing + training\n",
    "camembert_pipeline = camembert_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7VZVZsbvUwv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPMwQA8Uz0hjIDrnyygcMC2",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "who-wrote-this.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
