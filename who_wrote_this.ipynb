{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "who_wrote_this.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw6VsDhUun5n",
        "colab_type": "text"
      },
      "source": [
        "# Who wrote this : a framework for French novelist identification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rR8SIQ_ks-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liRJXYg6Cv2u",
        "colab_type": "code",
        "outputId": "824e3a52-1564-444f-cdd4-514f6b7fff66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "import gensim\n",
        "from gensim.models import Doc2Vec, FastText\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUk_HtdMolVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of available cores for parallel computing\n",
        "N_CORES = cpu_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPykVwoCzxbu",
        "colab_type": "text"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is9UbtTqWa9L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "a525a7c3-8bc1-418c-a8c1-f4370103041e"
      },
      "source": [
        "# Download data from the GitHub repository\n",
        "!wget https://raw.githubusercontent.com/meteve/NLP_project/master/data/corpus_train.csv\n",
        "!wget https://raw.githubusercontent.com/meteve/NLP_project/master/data/corpus_test.csv"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-27 14:19:59--  https://raw.githubusercontent.com/meteve/NLP_project/master/data/corpus_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18165744 (17M) [text/plain]\n",
            "Saving to: ‘corpus_train.csv’\n",
            "\n",
            "\rcorpus_train.csv      0%[                    ]       0  --.-KB/s               \rcorpus_train.csv    100%[===================>]  17.32M   103MB/s    in 0.2s    \n",
            "\n",
            "2020-03-27 14:19:59 (103 MB/s) - ‘corpus_train.csv’ saved [18165744/18165744]\n",
            "\n",
            "--2020-03-27 14:20:00--  https://raw.githubusercontent.com/meteve/NLP_project/master/data/corpus_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6894810 (6.6M) [text/plain]\n",
            "Saving to: ‘corpus_test.csv’\n",
            "\n",
            "corpus_test.csv     100%[===================>]   6.58M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-03-27 14:20:00 (57.1 MB/s) - ‘corpus_test.csv’ saved [6894810/6894810]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i0eCW7-DDDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import train data\n",
        "train_df = pd.read_csv('corpus_train.csv', sep='|')\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True) # Shuffle\n",
        "X_train = train_df['paragraph'].values\n",
        "y_labels_train = train_df['author'].values\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_labels_train)\n",
        "N_CLASSES = len(np.unique(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPnN3eBy3slZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import test data and build validation dataset\n",
        "test_df = pd.read_csv('corpus_test.csv', sep='|')\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True) # Shuffle\n",
        "X_val, X_test, y_val, y_test = train_test_split(test_df['paragraph'].values,\n",
        "                                                test_df['author'].values,\n",
        "                                                test_size=0.5, random_state=42)\n",
        "y_val = le.transform(y_val)\n",
        "y_test = le.transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk7Dfp3JKzTj",
        "colab_type": "code",
        "outputId": "593af0e5-552e-4f3e-f268-28b13fd3752a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train_df.head(5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraph</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Il se précipita donc vers cette maison, distan...</td>\n",
              "      <td>Verne</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>En face d'eux, la côte semée de villas descend...</td>\n",
              "      <td>Maupassant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Le mariage était fixé au 20 octobre, après la ...</td>\n",
              "      <td>Maupassant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Il y avait dans un coin de la chambre un vieux...</td>\n",
              "      <td>Hugo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-- Eh quoi! dit la reine quand le dernier d'en...</td>\n",
              "      <td>Dumas</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           paragraph      author\n",
              "0  Il se précipita donc vers cette maison, distan...       Verne\n",
              "1  En face d'eux, la côte semée de villas descend...  Maupassant\n",
              "2  Le mariage était fixé au 20 octobre, après la ...  Maupassant\n",
              "3  Il y avait dans un coin de la chambre un vieux...        Hugo\n",
              "4  -- Eh quoi! dit la reine quand le dernier d'en...       Dumas"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pc4i1aPKJqv",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSOiEE20z1o4",
        "colab_type": "text"
      },
      "source": [
        "### Baseline : TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOwk-ES44rEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ML pipeline : TF-IDF + SVM classifier\n",
        "\n",
        "tfidf_vecto = TfidfVectorizer()\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "\n",
        "tfidf_pipeline = Pipeline([\n",
        "                           ('tf-idf', tfidf_vecto),\n",
        "                           ('clf', clf)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KlP_Iw2oth4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keep sklearn preprocessing pipeline for later\n",
        "preprocessor = tfidf_vecto.build_analyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ML1EXEK2kA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing + training\n",
        "tfidf_pipeline = tfidf_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdyNC-ok3qxy",
        "colab_type": "code",
        "outputId": "93dc340a-e2c7-4372-a586-2bab74d45145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute predictions and validation score\n",
        "y_val_pred_tfidf = tfidf_pipeline.predict(X_val)\n",
        "tfidf_val_score = f1_score(y_val, y_val_pred_tfidf, average='micro')\n",
        "print('F1 score on validation set with TF-IDF :', \n",
        "      tfidf_val_score.round(2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set with TF-IDF : 0.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g88tOQuBz792",
        "colab_type": "text"
      },
      "source": [
        "### FastText (averaging of pre-trained word vectors)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9E444_cXwAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "7f8d5307-44e0-4c2f-d8bc-af464276730f"
      },
      "source": [
        "# Download and extract FastText French word vectors\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz\n",
        "!gunzip cc.fr.300.bin.gz"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-27 14:23:02--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4a8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4496886212 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.fr.300.bin.gz’\n",
            "\n",
            "cc.fr.300.bin.gz    100%[===================>]   4.19G  21.5MB/s    in 3m 1s   \n",
            "\n",
            "2020-03-27 14:26:04 (23.7 MB/s) - ‘cc.fr.300.bin.gz’ saved [4496886212/4496886212]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAYXl07XADFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Fasttext French word vectors\n",
        "fasttext = FastText.load_fasttext_format('cc.fr.300.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r151opCRr8B1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_wv_fasttext(text):\n",
        "    \"\"\"Compute average of FastText's word vectors for a given text.\"\"\"\n",
        "    if text:\n",
        "        tokens = preprocessor(text)\n",
        "        wv_mat = np.zeros((len(tokens), fasttext.vector_size))\n",
        "        for i, tok in enumerate(tokens):\n",
        "            try:\n",
        "                wv_mat[i] = fasttext.wv[tok]\n",
        "            except KeyError:\n",
        "                pass\n",
        "        text_vec = wv_mat.mean(axis=0)\n",
        "    else:\n",
        "        text_vec = np.zeros(fasttext.vector_size)\n",
        "    return text_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRfHhI-LuzPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_corpus_fasttext(corpus):\n",
        "    \"\"\"Parallelize preprocessing and document vectors computation.\"\"\"\n",
        "    with Pool(N_CORES) as p:\n",
        "        corpus_prepro = p.map(text_to_wv_fasttext, list(corpus))\n",
        "    return np.array(corpus_prepro)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV7aqaByn1B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextToWV(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Enable to use preprocessing function in a sklearn pipeline.\"\"\"\n",
        "    def __init__(self, preprocessor):\n",
        "        self.preprocessor = preprocessor\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return(self)\n",
        "\n",
        "    def transform(self, X):\n",
        "        return self.preprocessor(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sg3YBbgJ0ZPm",
        "colab": {}
      },
      "source": [
        "# Prediction pipeline\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "fasttext_pipeline = Pipeline([\n",
        "                              ('fasttext_average', TextToWV(preprocess_corpus_fasttext)),\n",
        "                              ('clf', clf)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTvo5xwMob3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing + training\n",
        "fasttext_pipeline = fasttext_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIVGLvOm0pY_",
        "colab_type": "code",
        "outputId": "bacc522c-3acb-4bf5-ba3c-573b8af4d501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute predictions and test score\n",
        "y_val_pred_fasttext = fasttext_pipeline.predict(X_val)\n",
        "val_score_fasttext = f1_score(y_val, y_val_pred_fasttext, average='micro')\n",
        "print('F1 score on validation set :',\n",
        "      val_score_fasttext.round(2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set : 0.35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL0DTOLbvYq1",
        "colab_type": "text"
      },
      "source": [
        "### Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztQM6FneveCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_d2v_corpus(corpus, tokens_only=False):\n",
        "    \"\"\"Tokenize and build corpus as expected by Gensim Doc2Vec class.\"\"\"\n",
        "    corpus_tokenized = []\n",
        "    for i, text in enumerate(corpus):\n",
        "        tokens = preprocessor(text)\n",
        "        if tokens_only:\n",
        "            corpus_tokenized.append(tokens)\n",
        "        else:\n",
        "            corpus_tokenized.append(TaggedDocument(tokens, [i]))\n",
        "    return corpus_tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krsC1SYh5ACx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Format train and validation corpus as required by Doc2Vec\n",
        "corpus_train_d2v = build_d2v_corpus(X_train, tokens_only=False)\n",
        "corpus_val_d2v = build_d2v_corpus(X_val, tokens_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryhxTy1C5wwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Doc2Vec model\n",
        "model = Doc2Vec(vector_size=50, min_count=2, epochs=10, workers=N_CORES)\n",
        "model.build_vocab(corpus_train_d2v)\n",
        "model.train(corpus_train_d2v, total_examples=model.corpus_count, \n",
        "            epochs=model.epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pLoVbMK8_DI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute document vectors on train and validation sets\n",
        "X_train_d2v = np.array([model.infer_vector(doc.words) for doc in corpus_train_d2v])\n",
        "X_val_d2v = np.array([model.infer_vector(doc) for doc in corpus_val_d2v])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe3LTThCAICg",
        "colab_type": "code",
        "outputId": "15585eb1-4ce9-433c-8678-4b531c15a372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute predictions and validation score\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "clf.fit(X_train_d2v, y_train)\n",
        "y_val_pred_d2v = clf.predict(X_val_d2v)\n",
        "val_score_d2v = f1_score(y_val, y_val_pred_d2v, average='micro')\n",
        "print('F1 score on validation set :', \n",
        "      val_score_d2v.round(2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set : 0.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUqdN5M90AQV",
        "colab_type": "text"
      },
      "source": [
        "### CamemBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6W9sKtFRXbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CorpusToTorchDataset(Dataset):\n",
        "    \"\"\"Convert corpus to tensors of token indices in CamemBERT vocabulary.\"\"\"\n",
        "    def __init__(self, corpus, labels, model_name, maxlen=100):\n",
        "        self.corpus = corpus\n",
        "        self.labels = labels\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.corpus)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # Select instance\n",
        "        sentence = self.corpus[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        # Preprocess data as required by BERT models\n",
        "        tokens = self.tokenizer.tokenize(sentence)\n",
        "        bos_token = self.tokenizer.cls_token\n",
        "        eos_token = self.tokenizer.sep_token\n",
        "        pad_token = self.tokenizer.pad_token\n",
        "        # Insert CLS and SEP tokens at beginning and end of sentence\n",
        "        tokens = [bos_token] + tokens + [eos_token]\n",
        "        if len(tokens) < self.maxlen:\n",
        "            # If sentence is shorter than maxlen, pad sentence using special \n",
        "            # padding token\n",
        "            tokens = tokens + [pad_token for _ in range(self.maxlen - len(tokens))]\n",
        "        else:\n",
        "            # Cut the sentence if it is longer than maxlen\n",
        "            tokens = tokens[:self.maxlen-1] + [eos_token]\n",
        "\n",
        "        # Convert tokens to tensor of indices in CamemBERT vocabulary\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
        "        # Get attention mask to distinguish padding tokens from actual tokens\n",
        "        pad_token_id = self.tokenizer.convert_tokens_to_ids(pad_token)\n",
        "        attn_mask = (tokens_ids_tensor != pad_token_id).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDnF51VmVtHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create instances of training and validation dataloaders\n",
        "\n",
        "BERT_MODEL_NAME = 'camembert-base'\n",
        "MAXLEN = 100\n",
        "BATCH_SIZE = 12\n",
        "\n",
        "train_set = CorpusToTorchDataset(X_train, y_train, model_name=BERT_MODEL_NAME, maxlen=100)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=N_CORES)\n",
        "\n",
        "val_set = CorpusToTorchDataset(X_val, y_val, model_name=BERT_MODEL_NAME, maxlen=100)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=N_CORES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ydN8F8gOUI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CamemBERTClassifier(nn.Module):\n",
        "    \"\"\"Perform fine-tuning and classification using CamemBERT.\"\"\"\n",
        "    def __init__(self, pretrained_model_name=BERT_MODEL_NAME):\n",
        "        super(CamemBERTClassifier, self).__init__()\n",
        "        # Load CamemBERT\n",
        "        self.encoder = AutoModel.from_pretrained(pretrained_model_name)\n",
        "        # Add an extra dense layer to perform classification\n",
        "        self.cls_layer = nn.Linear(self.encoder.pooler.dense.out_features, N_CLASSES)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        # Feed input to BERT model to obtain contextualized representations\n",
        "        cont_reps, _ = self.encoder(seq, attention_mask = attn_masks)\n",
        "        # Get representation of [CLS] head\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "        # Feed document representation to the classifying layer\n",
        "        logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4A_4QjGOUP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate CamemBERT classifier model\n",
        "camembert_clf = CamemBERTClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f14mz-vhsuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss and optimizer\n",
        "criterion = CrossEntropyLoss()\n",
        "opti = Adam(camembert_clf.parameters(), lr = 3e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZUQxW1biwti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, criterion, opti, train_loader, val_loader, max_eps=3, \n",
        "          gpu=True, print_every=100, validate_every=1):\n",
        "    \"\"\"Train a transformer model and compute loss on validation data.\"\"\"\n",
        "    if gpu:\n",
        "        model = model.to(\"cuda\")\n",
        "    # Unfreeze weights to allow fine tuning\n",
        "    model.train() \n",
        "\n",
        "    train_loss_total = 0\n",
        "    n_batch_train = 0\n",
        "    for ep in range(max_eps):\n",
        "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "            # Clear gradients (avoid accumulation)\n",
        "            opti.zero_grad()  \n",
        "            # Transfer tensors to GPU\n",
        "            if gpu:\n",
        "                seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "            # Compute logits\n",
        "            logits = model(seq, attn_masks)\n",
        "            # Compute batch loss\n",
        "            loss = criterion(logits, labels)\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            # Optimization step\n",
        "            opti.step()\n",
        "            # Accumulate train loss over batches\n",
        "            train_loss_total += loss.item()\n",
        "            n_batch_train += 1\n",
        "\n",
        "            # Compute average loss over the last `print_every` training batches\n",
        "            if print_every is not None and (it + 1) % print_every == 0:\n",
        "                print(f'Epoch {ep+1}, batch {it+1}. Average loss over last {print_every} training batches : {train_loss_total/n_batch_train}')\n",
        "                # Reinitialize accumulators\n",
        "                train_loss_total = 0\n",
        "                n_batch_train = 0\n",
        "\n",
        "        if validate_every is not None and ep % validate_every == 0:\n",
        "            # Evaluation on the validation set\n",
        "\n",
        "            predictions_val = []\n",
        "            true_labels_val = []\n",
        "            for it, (seq, attn_masks, labels) in enumerate(val_loader):\n",
        "                if gpu:\n",
        "                    seq, attn_masks = seq.cuda(), attn_masks.cuda()\n",
        "                # Compute logits without constructing the computing graph\n",
        "                # (only needed for backprop)\n",
        "                with torch.no_grad():\n",
        "                    logits_val = model(seq, attn_masks)\n",
        "                preds_batch = torch.argmax(logits_val, 1).cpu().numpy()\n",
        "                predictions_val.extend(preds_batch)\n",
        "                true_labels_val.extend(labels.numpy())\n",
        "\n",
        "            val_f1 = f1_score(true_labels_val, predictions_val, average='micro')\n",
        "            print('------------------------------------------------------------')\n",
        "            print(\"Epoch {} complete. F1 score on validation data : {}\".format(ep+1, val_f1))\n",
        "            print('------------------------------------------------------------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nfxNPWenHb-",
        "colab_type": "code",
        "outputId": "ba12aef4-bd13-40e2-c88d-52a0773fb3d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Enforce deterministic behavior to ensure reproducibility of the results\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "train(camembert_clf, criterion, opti, train_loader, val_loader,\n",
        "      max_eps=1, gpu=True, print_every=500, validate_every=1)\n",
        "\n",
        "# Grid search (only 1 epoch each time, systematic overtraining above that) :\n",
        "# lr = 5e-5 => val_f1 = 0.49\n",
        "# lr = 3e-5 => val_f1 = 0.52"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, batch 500. Average loss over last 500 training batches : 1.6164042003154755\n",
            "Epoch 1, batch 1000. Average loss over last 500 training batches : 1.0134558594226837\n",
            "Epoch 1, batch 1500. Average loss over last 500 training batches : 0.7353367038667202\n",
            "Epoch 1, batch 2000. Average loss over last 500 training batches : 0.611015151232481\n",
            "Epoch 1, batch 2500. Average loss over last 500 training batches : 0.5248016767948865\n",
            "Epoch 1, batch 3000. Average loss over last 500 training batches : 0.4910539143830538\n",
            "Epoch 1, batch 3500. Average loss over last 500 training batches : 0.4564877462014556\n",
            "------------------------------------------------------------\n",
            "Epoch 1 complete. F1 score on validation data : 0.5199483689274819\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFNaQyUBKf6B",
        "colab_type": "text"
      },
      "source": [
        "# Final evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3tvHk02Kg4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TFIDF\n",
        "\n",
        "y_test_pred_tfidf = tfidf_pipeline.predict(X_test)\n",
        "test_score_tfidf = f1_score(y_test, y_test_pred_tfidf, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lLVo45ILnqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FastText\n",
        "\n",
        "y_test_pred_fasttext = fasttext_pipeline.predict(X_test)\n",
        "test_score_fasttext = f1_score(y_test, y_test_pred_fasttext, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxG0wUKGQ7PM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# doc2vec\n",
        "\n",
        "corpus_test_d2v = build_d2v_corpus(X_test, tokens_only=True)\n",
        "X_test_d2v = np.array([model.infer_vector(doc) for doc in corpus_test_d2v])\n",
        "y_test_pred_d2v = clf.predict(X_test_d2v)\n",
        "test_score_d2v = f1_score(y_test, y_test_pred_d2v, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTCCjA3yR0o0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CamemBERT\n",
        "\n",
        "# Create instance of test dataloader\n",
        "test_set = CorpusToTorchDataset(X_test, y_test, model_name=BERT_MODEL_NAME, maxlen=100)\n",
        "test_loader = DataLoader(test_set, batch_size = 12, num_workers = N_CORES)\n",
        "\n",
        "def eval(model, test_loader, gpu=True):\n",
        "    \"\"\"Compute predictions of a trained transforme model on test data.\"\"\"\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    for it, (seq, attn_masks, labels) in enumerate(test_loader):\n",
        "        if gpu:\n",
        "            seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "        # Compute logits without constructing the computing graph\n",
        "        # (only needed for backprop)\n",
        "        with torch.no_grad():\n",
        "            logits = model(seq, attn_masks)\n",
        "        # Compute predictions from logits and store them as arrays\n",
        "        preds_batch = torch.argmax(logits, 1).cpu().numpy()\n",
        "        predictions.extend(preds_batch)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "y_test_pred_camembert = eval(camembert_clf, test_loader)\n",
        "test_score_camembert = f1_score(y_test, y_test_pred_camembert, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7Xu42gIhQd_",
        "colab_type": "code",
        "outputId": "f7714a35-0e4c-410d-e5a0-c3aa6a8a9794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "# Compare performances\n",
        "models = ['TF-IDF', 'FastText', 'Doc2Vec', 'CamemBERT']\n",
        "scores = [test_score_tfidf, test_score_fasttext, test_score_d2v, test_score_camembert]\n",
        "df_scores = pd.DataFrame(zip(models, scores), columns=['Model', 'F1 score'])\n",
        "df_scores.sort_values('F1 score', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>F1 score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TF-IDF</td>\n",
              "      <td>0.515898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CamemBERT</td>\n",
              "      <td>0.515312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>0.388948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FastText</td>\n",
              "      <td>0.350933</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Model  F1 score\n",
              "0     TF-IDF  0.515898\n",
              "3  CamemBERT  0.515312\n",
              "2    Doc2Vec  0.388948\n",
              "1   FastText  0.350933"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    }
  ]
}