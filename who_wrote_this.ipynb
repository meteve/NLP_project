{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "who_wrote_this.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9bebfcf9d7a34898b9c1133d6bd96cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7941a497db0e4815a5abd281eab88373",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9c55992210f34fb68a3fad6b8c52ad3b",
              "IPY_MODEL_02f7897d71fb4427958bbea9156f9f51"
            ]
          }
        },
        "7941a497db0e4815a5abd281eab88373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c55992210f34fb68a3fad6b8c52ad3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f637b367b9a5440ab2e4ac69f8f400d2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 637,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 637,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d8a2a51402d42e592774431e02b2fff"
          }
        },
        "02f7897d71fb4427958bbea9156f9f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e85a326147604321a88acac05e4111f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 637/637 [00:01&lt;00:00, 393B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d7738f9de514443872c5fec89d743eb"
          }
        },
        "f637b367b9a5440ab2e4ac69f8f400d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d8a2a51402d42e592774431e02b2fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e85a326147604321a88acac05e4111f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d7738f9de514443872c5fec89d743eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b746df3ea214192ba84e4b47b697447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce51deaca2374ebe9406e99c39979c57",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a7d7ed01a99d45bc8363f1edf706e3e7",
              "IPY_MODEL_854e39b522d040b9acc247f117c3f980"
            ]
          }
        },
        "ce51deaca2374ebe9406e99c39979c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7d7ed01a99d45bc8363f1edf706e3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ecd2bdb8a724fae89255fe48f4ca7aa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 810912,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 810912,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a44ea368615f46a1bcc1c9abd22b138e"
          }
        },
        "854e39b522d040b9acc247f117c3f980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_39e3622d029a40d596c237d66e082646",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 811k/811k [00:50&lt;00:00, 16.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_462d31f6a55442a69f753befc34a10d0"
          }
        },
        "8ecd2bdb8a724fae89255fe48f4ca7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a44ea368615f46a1bcc1c9abd22b138e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39e3622d029a40d596c237d66e082646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "462d31f6a55442a69f753befc34a10d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a78cbb06ffd149e795524e6b38775279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a9668d0f114a45159d9a7e858f75323d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69ce3f1fc87748f99b59d1e637ba63ea",
              "IPY_MODEL_8b9e5b8b248e4067b3b364b014ab3056"
            ]
          }
        },
        "a9668d0f114a45159d9a7e858f75323d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69ce3f1fc87748f99b59d1e637ba63ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7499bf8146bd48648178031d5d256d06",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 445032417,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445032417,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0eaffe86554b40dabfde2a2ce8a89582"
          }
        },
        "8b9e5b8b248e4067b3b364b014ab3056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_669df74295514a1e93aa3452c73b499f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:37&lt;00:00, 11.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4545f94179df4e90bb9647b60ece1272"
          }
        },
        "7499bf8146bd48648178031d5d256d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0eaffe86554b40dabfde2a2ce8a89582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "669df74295514a1e93aa3452c73b499f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4545f94179df4e90bb9647b60ece1272": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw6VsDhUun5n",
        "colab_type": "text"
      },
      "source": [
        "# Who wrote this : a framework for French novelist identification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rR8SIQ_ks-E",
        "colab_type": "code",
        "outputId": "006fb137-4725-47ca-b7d5-b0dec4ecf45a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install unidecode\n",
        "!pip install transformers\n",
        "!python -m spacy download fr_core_news_md"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 29.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a0/32e3a4501ef480f7ea01aac329a716132f32f7911ef1c2fac228acc57ca7/transformers-2.6.0-py3-none-any.whl (540kB)\n",
            "\u001b[K     |████████████████████████████████| 542kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.27)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 18.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 42.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.27)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=e3fbec19081189c2f33c9d3b29b9cca56138eee06efd0da1ccdd5886bfa201f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.6.0\n",
            "Collecting fr_core_news_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-2.2.5/fr_core_news_md-2.2.5.tar.gz (88.6MB)\n",
            "\u001b[K     |████████████████████████████████| 88.6MB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (46.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.18.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (1.5.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: fr-core-news-md\n",
            "  Building wheel for fr-core-news-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-md: filename=fr_core_news_md-2.2.5-cp36-none-any.whl size=90338488 sha256=cf44a8aff8a2bdbb875bcbf24a74442c5354a49b8b47dc3bb373886859bbf59b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zauex4ds/wheels/c6/18/b6/f628642acc7872a53cf81269dd1c394d96da69564ccfac5425\n",
            "Successfully built fr-core-news-md\n",
            "Installing collected packages: fr-core-news-md\n",
            "Successfully installed fr-core-news-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liRJXYg6Cv2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "import unidecode\n",
        "import urllib.request\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "import spacy\n",
        "import fr_core_news_md\n",
        "import gensim\n",
        "from gensim.models import Doc2Vec, FastText\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUk_HtdMolVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of available cores for parallel computing\n",
        "N_CORES = cpu_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPykVwoCzxbu",
        "colab_type": "text"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is9UbtTqWa9L",
        "colab_type": "code",
        "outputId": "366f0154-5ce2-46ac-9eb7-f27535d7ceef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "# Download data from the GitHub repository\n",
        "!wget https://raw.githubusercontent.com/meteve/NLP_project/master/data/corpus_train.csv\n",
        "!wget https://raw.githubusercontent.com/meteve/NLP_project/master/data/corpus_test.csv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-27 20:34:09--  https://raw.githubusercontent.com/meteve/NLP_project/master/data/corpus_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18165744 (17M) [text/plain]\n",
            "Saving to: ‘corpus_train.csv’\n",
            "\n",
            "corpus_train.csv    100%[===================>]  17.32M   107MB/s    in 0.2s    \n",
            "\n",
            "2020-03-27 20:34:11 (107 MB/s) - ‘corpus_train.csv’ saved [18165744/18165744]\n",
            "\n",
            "--2020-03-27 20:34:14--  https://raw.githubusercontent.com/meteve/NLP_project/master/data/corpus_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6894810 (6.6M) [text/plain]\n",
            "Saving to: ‘corpus_test.csv’\n",
            "\n",
            "corpus_test.csv     100%[===================>]   6.58M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-03-27 20:34:16 (50.3 MB/s) - ‘corpus_test.csv’ saved [6894810/6894810]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i0eCW7-DDDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import train data\n",
        "train_df = pd.read_csv('corpus_train.csv', sep='|')\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True) # Shuffle\n",
        "X_train = train_df['paragraph'].values\n",
        "y_labels_train = train_df['author'].values\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_labels_train)\n",
        "N_CLASSES = len(np.unique(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPnN3eBy3slZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import test data and build validation dataset\n",
        "test_df = pd.read_csv('corpus_test.csv', sep='|')\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True) # Shuffle\n",
        "X_val, X_test, y_val, y_test = train_test_split(test_df['paragraph'].values,\n",
        "                                                test_df['author'].values,\n",
        "                                                test_size=0.5, random_state=42)\n",
        "y_val = le.transform(y_val)\n",
        "y_test = le.transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk7Dfp3JKzTj",
        "colab_type": "code",
        "outputId": "6bc61538-5695-411f-fdbc-64a3eac36390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train_df.head(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraph</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>--Je vais retirer l'échelle, dit-il, pour qu'e...</td>\n",
              "      <td>Stendhal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tout le petit bois conspire pour l'empêcher de...</td>\n",
              "      <td>Daudet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Frédéric passa la sienne trois jours après. Av...</td>\n",
              "      <td>Flaubert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-- Oui, reprit Porthos en se ravisant; mais un...</td>\n",
              "      <td>Dumas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>«Renvoyer le comte... me trouver seule avec lu...</td>\n",
              "      <td>Stendhal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           paragraph    author\n",
              "0  --Je vais retirer l'échelle, dit-il, pour qu'e...  Stendhal\n",
              "1  Tout le petit bois conspire pour l'empêcher de...    Daudet\n",
              "2  Frédéric passa la sienne trois jours après. Av...  Flaubert\n",
              "3  -- Oui, reprit Porthos en se ravisant; mais un...     Dumas\n",
              "4  «Renvoyer le comte... me trouver seule avec lu...  Stendhal"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pc4i1aPKJqv",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSOiEE20z1o4",
        "colab_type": "text"
      },
      "source": [
        "### Baseline : TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENoBUodrpxwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "URL = 'https://raw.githubusercontent.com/stopwords-iso/stopwords-fr/master/stopwords-fr.txt'\n",
        "response = urllib.request.urlopen(URL)\n",
        "stopwords = response.read().decode('utf-8').splitlines()\n",
        "stopwords = [unidecode.unidecode(x) for x in stopwords]\n",
        "stopwords.append('quelqu') # Make stopwords consistent with scikit tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOwk-ES44rEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ML pipeline : TF-IDF + SVM classifier\n",
        "\n",
        "tfidf_vecto = TfidfVectorizer(stop_words=stopwords)\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "\n",
        "tfidf_pipeline = Pipeline([\n",
        "                           ('tf-idf', tfidf_vecto),\n",
        "                           ('clf', clf)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KlP_Iw2oth4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keep sklearn preprocessing pipeline for later\n",
        "preprocessor = tfidf_vecto.build_analyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ML1EXEK2kA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing + training\n",
        "tfidf_pipeline = tfidf_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdyNC-ok3qxy",
        "colab_type": "code",
        "outputId": "e0c928cd-768f-460c-dfd7-55b21023335e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Compute predictions and validation score\n",
        "y_val_pred_tfidf = tfidf_pipeline.predict(X_val)\n",
        "tfidf_val_score = f1_score(y_val, y_val_pred_tfidf, average='micro')\n",
        "print('F1 score on validation set with TF-IDF :', \n",
        "      tfidf_val_score.round(2))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set with TF-IDF : 0.48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSb0A41gsP8z",
        "colab_type": "code",
        "outputId": "5e1c7237-2e99-4a2e-ec26-4a9dc8832e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Compute predictions and score on train set\n",
        "y_train_pred_tfidf = tfidf_pipeline.predict(X_train)\n",
        "tfidf_train_score = f1_score(y_train, y_train_pred_tfidf, average='micro')\n",
        "print('F1 score on train set with TF-IDF :', \n",
        "      tfidf_train_score.round(2))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on train set with TF-IDF : 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpFzXyGUsN9L",
        "colab_type": "text"
      },
      "source": [
        "The train score indicates that the baseline overfits the training data. It may be due to the fact that there are different books in the train and test sets. Some locations and characters which are present in the books of the training set may have a strong influence on the training of the model. We first compute tf-idf weights for the well classified paragraphs of the train set, and look at the most important words for each author in terms of tf-idf weights.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8P2kyv1sSKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top_tfidf_feats(row, features, top_n):\n",
        "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
        "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
        "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
        "    df = pd.DataFrame(top_feats)\n",
        "    df.columns = ['feature', 'tfidf']\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KINbMCHcsU4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tfidf_weights_by_author(author, NER=False, top_n=20):\n",
        "    '''Return words with high tfidf weights, for well-classified paragraphs of an author with or without NER'''\n",
        "    y_true = y_train\n",
        "    \n",
        "    if NER == True:\n",
        "        y_pred = y_train_pred_tfidf_ner\n",
        "        pipe = tfidf_pipeline_ner\n",
        "        X = X_train_ner\n",
        "    else:\n",
        "        y_pred = y_train_pred_tfidf\n",
        "        pipe = tfidf_pipeline\n",
        "        X = X_train\n",
        "        \n",
        "    \n",
        "    if type(author) == str:\n",
        "        author_index = list(le.classes_).index(author)\n",
        "    elif type(author) == int:\n",
        "        author_index = author\n",
        "   \n",
        "    # keep well classified paragraphs of the auhtor\n",
        "    well_classif_indexes = ((y_true == author_index) & (y_pred == author_index))\n",
        "    X_train_well_classif = X[well_classif_indexes]\n",
        "    \n",
        "    # get tf-idf vectors\n",
        "    vec = tfidf_pipeline.named_steps['tf-idf']\n",
        "    Xtr = vec.transform(X_train_well_classif)\n",
        "    features = vec.get_feature_names()\n",
        "    \n",
        "    # get mean tf-idf scores\n",
        "    D = Xtr.toarray()\n",
        "    tfidf_means = np.mean(D, axis=0)\n",
        "    \n",
        "    return top_tfidf_feats(tfidf_means, features, top_n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbmVlzZtyGRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tfidf_weights_by_author(author, y_true, y_pred, X, top_n=20):\n",
        "    '''Return words with high tfidf weights, for well-classified paragraphs of an author with or without NER'''        \n",
        "    \n",
        "    if type(author) == str:\n",
        "        author_index = list(le.classes_).index(author)\n",
        "    elif type(author) == int:\n",
        "        author_index = author\n",
        "   \n",
        "    # keep well classified paragraphs of the auhtor\n",
        "    well_classif_indexes = ((y_true == author_index) & (y_pred == author_index))\n",
        "    X_train_well_classif = X[well_classif_indexes]\n",
        "    \n",
        "    # get tf-idf vectors\n",
        "    vec = tfidf_pipeline.named_steps['tf-idf']\n",
        "    Xtr = vec.transform(X_train_well_classif)\n",
        "    features = vec.get_feature_names()\n",
        "    \n",
        "    # get mean tf-idf scores\n",
        "    D = Xtr.toarray()\n",
        "    tfidf_means = np.mean(D, axis=0)\n",
        "    \n",
        "    return top_tfidf_feats(tfidf_means, features, top_n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PoT5OE3sWrw",
        "colab_type": "code",
        "outputId": "7b4301f3-a449-47e6-8b0b-34ef3db49175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "get_tfidf_weights_by_author(author='Maupassant', y_true=y_train, y_pred=y_train_pred_tfidf, X=X_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jeanne</td>\n",
              "      <td>0.033423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>duroy</td>\n",
              "      <td>0.024628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>walter</td>\n",
              "      <td>0.014932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>était</td>\n",
              "      <td>0.013707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>forestier</td>\n",
              "      <td>0.012990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>julien</td>\n",
              "      <td>0.012916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>mme</td>\n",
              "      <td>0.011623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>femme</td>\n",
              "      <td>0.011069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ça</td>\n",
              "      <td>0.010379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>georges</td>\n",
              "      <td>0.009579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>point</td>\n",
              "      <td>0.009378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>roy</td>\n",
              "      <td>0.009029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>là</td>\n",
              "      <td>0.008427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>où</td>\n",
              "      <td>0.008198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>bras</td>\n",
              "      <td>0.007904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>faire</td>\n",
              "      <td>0.007613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>temps</td>\n",
              "      <td>0.007502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>madeleine</td>\n",
              "      <td>0.007380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>mère</td>\n",
              "      <td>0.007323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>petite</td>\n",
              "      <td>0.007314</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      feature     tfidf\n",
              "0      jeanne  0.033423\n",
              "1       duroy  0.024628\n",
              "2      walter  0.014932\n",
              "3       était  0.013707\n",
              "4   forestier  0.012990\n",
              "5      julien  0.012916\n",
              "6         mme  0.011623\n",
              "7       femme  0.011069\n",
              "8          ça  0.010379\n",
              "9     georges  0.009579\n",
              "10      point  0.009378\n",
              "11        roy  0.009029\n",
              "12         là  0.008427\n",
              "13         où  0.008198\n",
              "14       bras  0.007904\n",
              "15      faire  0.007613\n",
              "16      temps  0.007502\n",
              "17  madeleine  0.007380\n",
              "18       mère  0.007323\n",
              "19     petite  0.007314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMlOaXrXtC0r",
        "colab_type": "text"
      },
      "source": [
        "A relatively high number of proper nouns have a high tf-idf weight in the previous model. That's why we implement a Named Entity Recognition (NER) procedure and evaluate whether it reduces the overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfwlFsgYw8Rf",
        "colab_type": "text"
      },
      "source": [
        "### NER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdaBYrY1xGKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = fr_core_news_md.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LThQ2jrSx7Lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_named_entities(paragraph): \n",
        "  \"\"\"remove the named entities from a paragraph\"\"\"\n",
        "  doc = nlp(paragraph)\n",
        "  names = []\n",
        "  for ent in doc.ents:\n",
        "      # list of all the named entities recognized in the paragraph\n",
        "      names.append(ent)\n",
        "  # keep unique elements and convert to string    \n",
        "  names = set([str(x) for x in names])\n",
        "    \n",
        "  # remove named entities from the paragraph\n",
        "  paragraph_no_names = paragraph\n",
        "  for name in names:\n",
        "      paragraph_no_names = paragraph_no_names.replace(name, '')\n",
        "        \n",
        "  return paragraph_no_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ers1YsXS8a7M",
        "colab_type": "code",
        "outputId": "d7ea3228-0f53-43d5-9213-4e934586467c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        }
      },
      "source": [
        "X_train_ner = []\n",
        "\n",
        "for i, par in enumerate(X_train):\n",
        "  par_ner = remove_named_entities(par)\n",
        "  X_train_ner.append(par_ner)\n",
        "  if i%1000 == 0:\n",
        "        print(i)\n",
        "\n",
        "X_train_ner = np.array(X_train_ner)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XButdewn9e0Z",
        "colab_type": "code",
        "outputId": "fa6ebf9c-e3c8-48c5-8f34-db446937866a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "X_val_ner = []\n",
        "\n",
        "for i, par in enumerate(X_val):\n",
        "  par_ner = remove_named_entities(par)\n",
        "  X_val_ner.append(par_ner)\n",
        "  if i%1000 == 0:\n",
        "        print(i)\n",
        "\n",
        "X_val_ner = np.array(X_val_ner)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwveZxS42Jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = tfidf_pipeline.fit(X_train_ner, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r9ftlb6xQCm",
        "colab_type": "code",
        "outputId": "724377f3-b3ee-4651-8742-8df16111d648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Compute predictions and score on train set AFTER NER procedure\n",
        "y_train_pred_tfidf_ner = tfidf_pipeline.predict(X_train_ner)\n",
        "tfidf_train_score_ner = f1_score(y_train, y_train_pred_tfidf_ner, average='micro')\n",
        "print('F1 score on train set with TF-IDF after NER:', \n",
        "      tfidf_train_score_ner.round(2))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on train set with TF-IDF after NER: 0.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0KOE89q4U90",
        "colab_type": "text"
      },
      "source": [
        "The train score is much lower after removing the proper nouns in the paragraphs. The overfitting was partially due to the presence of such proper nouns. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXg9qpvp788m",
        "colab_type": "code",
        "outputId": "cd2b2811-3ebb-4a9f-9116-9a2c26cbb6e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Compute predictions and validation score AFTER NER procedure\n",
        "y_val_pred_tfidf_ner = tfidf_pipeline.predict(X_val_ner)\n",
        "tfidf_val_score_ner = f1_score(y_val, y_val_pred_tfidf_ner, average='micro')\n",
        "print('F1 score on validation set with TF-IDF after NER:', \n",
        "      tfidf_val_score_ner.round(2))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set with TF-IDF after NER: 0.42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOLRUrFLuSrP",
        "colab_type": "text"
      },
      "source": [
        "The validation score is lower when we remove the proper nouns of the paragraphs. This suggests that some names may appear in different books of the same author, and can be helpful for the predictions. We explore the words that have the highest tf-idf weights after NER procedure, even if we choose to keep the proper nouns in the paragraphs in the following models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er_AgKU6shFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "49f828b1-1de5-4db1-c9a3-c364511eeada"
      },
      "source": [
        "get_tfidf_weights_by_author(author='Maupassant', y_true=y_train, y_pred=y_train_pred_tfidf_ner, X=X_train_ner)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>était</td>\n",
              "      <td>0.012964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>femme</td>\n",
              "      <td>0.011081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>point</td>\n",
              "      <td>0.010577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>là</td>\n",
              "      <td>0.008892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bras</td>\n",
              "      <td>0.008730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>mère</td>\n",
              "      <td>0.008695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>baron</td>\n",
              "      <td>0.008583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>où</td>\n",
              "      <td>0.008556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>semblait</td>\n",
              "      <td>0.008394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>petite</td>\n",
              "      <td>0.008137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>allait</td>\n",
              "      <td>0.007882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>mit</td>\n",
              "      <td>0.007613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>coup</td>\n",
              "      <td>0.007575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>temps</td>\n",
              "      <td>0.007134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>mains</td>\n",
              "      <td>0.007100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>tête</td>\n",
              "      <td>0.007057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>faire</td>\n",
              "      <td>0.007043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>même</td>\n",
              "      <td>0.007021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>petit</td>\n",
              "      <td>0.006930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>yeux</td>\n",
              "      <td>0.006920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature     tfidf\n",
              "0      était  0.012964\n",
              "1      femme  0.011081\n",
              "2      point  0.010577\n",
              "3         là  0.008892\n",
              "4       bras  0.008730\n",
              "5       mère  0.008695\n",
              "6      baron  0.008583\n",
              "7         où  0.008556\n",
              "8   semblait  0.008394\n",
              "9     petite  0.008137\n",
              "10    allait  0.007882\n",
              "11       mit  0.007613\n",
              "12      coup  0.007575\n",
              "13     temps  0.007134\n",
              "14     mains  0.007100\n",
              "15      tête  0.007057\n",
              "16     faire  0.007043\n",
              "17      même  0.007021\n",
              "18     petit  0.006930\n",
              "19      yeux  0.006920"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOzb6bGBy4BA",
        "colab_type": "text"
      },
      "source": [
        "This analysis enables us to check whether the proper nouns were removed in the NER procedure. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g88tOQuBz792",
        "colab_type": "text"
      },
      "source": [
        "### FastText (averaging of pre-trained word vectors)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9E444_cXwAy",
        "colab_type": "code",
        "outputId": "006a5aaa-1484-4142-9537-6e6adce72f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# Download and extract FastText French word vectors\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz\n",
        "!gunzip cc.fr.300.bin.gz"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-27 21:05:59--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4b8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4496886212 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.fr.300.bin.gz’\n",
            "\n",
            "cc.fr.300.bin.gz    100%[===================>]   4.19G  11.4MB/s    in 6m 26s  \n",
            "\n",
            "2020-03-27 21:12:27 (11.1 MB/s) - ‘cc.fr.300.bin.gz’ saved [4496886212/4496886212]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAYXl07XADFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Fasttext French word vectors\n",
        "fasttext = FastText.load_fasttext_format('cc.fr.300.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r151opCRr8B1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_wv_fasttext(text):\n",
        "    \"\"\"Compute average of FastText's word vectors for a given text.\"\"\"\n",
        "    if text:\n",
        "        tokens = preprocessor(text)\n",
        "        wv_mat = np.zeros((len(tokens), fasttext.vector_size))\n",
        "        for i, tok in enumerate(tokens):\n",
        "            try:\n",
        "                wv_mat[i] = fasttext.wv[tok]\n",
        "            except KeyError:\n",
        "                pass\n",
        "        text_vec = wv_mat.mean(axis=0)\n",
        "    else:\n",
        "        text_vec = np.zeros(fasttext.vector_size)\n",
        "    return text_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRfHhI-LuzPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_corpus_fasttext(corpus):\n",
        "    \"\"\"Parallelize preprocessing and document vectors computation.\"\"\"\n",
        "    with Pool(N_CORES) as p:\n",
        "        corpus_prepro = p.map(text_to_wv_fasttext, list(corpus))\n",
        "    return np.array(corpus_prepro)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV7aqaByn1B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextToWV(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Enable to use preprocessing function in a sklearn pipeline.\"\"\"\n",
        "    def __init__(self, preprocessor):\n",
        "        self.preprocessor = preprocessor\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return(self)\n",
        "\n",
        "    def transform(self, X):\n",
        "        return self.preprocessor(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sg3YBbgJ0ZPm",
        "colab": {}
      },
      "source": [
        "# Prediction pipeline\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "fasttext_pipeline = Pipeline([\n",
        "                              ('fasttext_average', TextToWV(preprocess_corpus_fasttext)),\n",
        "                              ('clf', clf)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTvo5xwMob3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing + training\n",
        "fasttext_pipeline = fasttext_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIVGLvOm0pY_",
        "colab_type": "code",
        "outputId": "6db1cbc4-fe8e-4075-9fba-61d95a70f645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Compute predictions and test score\n",
        "y_val_pred_fasttext = fasttext_pipeline.predict(X_val)\n",
        "val_score_fasttext = f1_score(y_val, y_val_pred_fasttext, average='micro')\n",
        "print('F1 score on validation set :',\n",
        "      val_score_fasttext.round(2))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set : 0.33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL0DTOLbvYq1",
        "colab_type": "text"
      },
      "source": [
        "### Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztQM6FneveCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_d2v_corpus(corpus, tokens_only=False):\n",
        "    \"\"\"Tokenize and build corpus as expected by Gensim Doc2Vec class.\"\"\"\n",
        "    corpus_tokenized = []\n",
        "    for i, text in enumerate(corpus):\n",
        "        tokens = preprocessor(text)\n",
        "        if tokens_only:\n",
        "            corpus_tokenized.append(tokens)\n",
        "        else:\n",
        "            corpus_tokenized.append(TaggedDocument(tokens, [i]))\n",
        "    return corpus_tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krsC1SYh5ACx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Format train and validation corpus as required by Doc2Vec\n",
        "corpus_train_d2v = build_d2v_corpus(X_train, tokens_only=False)\n",
        "corpus_val_d2v = build_d2v_corpus(X_val, tokens_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryhxTy1C5wwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Doc2Vec model\n",
        "model = Doc2Vec(vector_size=50, min_count=2, epochs=10, workers=N_CORES)\n",
        "model.build_vocab(corpus_train_d2v)\n",
        "model.train(corpus_train_d2v, total_examples=model.corpus_count, \n",
        "            epochs=model.epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pLoVbMK8_DI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute document vectors on train and validation sets\n",
        "X_train_d2v = np.array([model.infer_vector(doc.words) for doc in corpus_train_d2v])\n",
        "X_val_d2v = np.array([model.infer_vector(doc) for doc in corpus_val_d2v])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe3LTThCAICg",
        "colab_type": "code",
        "outputId": "392d2f6a-7ef7-4be5-f31b-f9578ecb3ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Compute predictions and validation score\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "clf.fit(X_train_d2v, y_train)\n",
        "y_val_pred_d2v = clf.predict(X_val_d2v)\n",
        "val_score_d2v = f1_score(y_val, y_val_pred_d2v, average='micro')\n",
        "print('F1 score on validation set :', \n",
        "      val_score_d2v.round(2))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set : 0.37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUqdN5M90AQV",
        "colab_type": "text"
      },
      "source": [
        "### CamemBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6W9sKtFRXbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CorpusToTorchDataset(Dataset):\n",
        "    \"\"\"Convert corpus to tensors of token indices in CamemBERT vocabulary.\"\"\"\n",
        "    def __init__(self, corpus, labels, model_name, maxlen=100):\n",
        "        self.corpus = corpus\n",
        "        self.labels = labels\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.corpus)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # Select instance\n",
        "        sentence = self.corpus[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        # Preprocess data as required by BERT models\n",
        "        tokens = self.tokenizer.tokenize(sentence)\n",
        "        bos_token = self.tokenizer.cls_token\n",
        "        eos_token = self.tokenizer.sep_token\n",
        "        pad_token = self.tokenizer.pad_token\n",
        "        # Insert CLS and SEP tokens at beginning and end of sentence\n",
        "        tokens = [bos_token] + tokens + [eos_token]\n",
        "        if len(tokens) < self.maxlen:\n",
        "            # If sentence is shorter than maxlen, pad sentence using special \n",
        "            # padding token\n",
        "            tokens = tokens + [pad_token for _ in range(self.maxlen - len(tokens))]\n",
        "        else:\n",
        "            # Cut the sentence if it is longer than maxlen\n",
        "            tokens = tokens[:self.maxlen-1] + [eos_token]\n",
        "\n",
        "        # Convert tokens to tensor of indices in CamemBERT vocabulary\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
        "        # Get attention mask to distinguish padding tokens from actual tokens\n",
        "        pad_token_id = self.tokenizer.convert_tokens_to_ids(pad_token)\n",
        "        attn_mask = (tokens_ids_tensor != pad_token_id).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDnF51VmVtHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "9bebfcf9d7a34898b9c1133d6bd96cfe",
            "7941a497db0e4815a5abd281eab88373",
            "9c55992210f34fb68a3fad6b8c52ad3b",
            "02f7897d71fb4427958bbea9156f9f51",
            "f637b367b9a5440ab2e4ac69f8f400d2",
            "5d8a2a51402d42e592774431e02b2fff",
            "e85a326147604321a88acac05e4111f2",
            "0d7738f9de514443872c5fec89d743eb",
            "2b746df3ea214192ba84e4b47b697447",
            "ce51deaca2374ebe9406e99c39979c57",
            "a7d7ed01a99d45bc8363f1edf706e3e7",
            "854e39b522d040b9acc247f117c3f980",
            "8ecd2bdb8a724fae89255fe48f4ca7aa",
            "a44ea368615f46a1bcc1c9abd22b138e",
            "39e3622d029a40d596c237d66e082646",
            "462d31f6a55442a69f753befc34a10d0"
          ]
        },
        "outputId": "0c9a09f8-29ff-4ff1-8ee1-b3b88fde9ed5"
      },
      "source": [
        "# Create instances of training and validation dataloaders\n",
        "\n",
        "BERT_MODEL_NAME = 'camembert-base'\n",
        "MAXLEN = 100\n",
        "BATCH_SIZE = 12\n",
        "\n",
        "train_set = CorpusToTorchDataset(X_train, y_train, model_name=BERT_MODEL_NAME, maxlen=100)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=N_CORES)\n",
        "\n",
        "val_set = CorpusToTorchDataset(X_val, y_val, model_name=BERT_MODEL_NAME, maxlen=100)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=N_CORES)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bebfcf9d7a34898b9c1133d6bd96cfe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=637, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b746df3ea214192ba84e4b47b697447",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=810912, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ydN8F8gOUI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CamemBERTClassifier(nn.Module):\n",
        "    \"\"\"Perform fine-tuning and classification using CamemBERT.\"\"\"\n",
        "    def __init__(self, pretrained_model_name=BERT_MODEL_NAME):\n",
        "        super(CamemBERTClassifier, self).__init__()\n",
        "        # Load CamemBERT\n",
        "        self.encoder = AutoModel.from_pretrained(pretrained_model_name)\n",
        "        # Add an extra dense layer to perform classification\n",
        "        self.cls_layer = nn.Linear(self.encoder.pooler.dense.out_features, N_CLASSES)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        # Feed input to BERT model to obtain contextualized representations\n",
        "        cont_reps, _ = self.encoder(seq, attention_mask = attn_masks)\n",
        "        # Get representation of [CLS] head\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "        # Feed document representation to the classifying layer\n",
        "        logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4A_4QjGOUP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "a78cbb06ffd149e795524e6b38775279",
            "a9668d0f114a45159d9a7e858f75323d",
            "69ce3f1fc87748f99b59d1e637ba63ea",
            "8b9e5b8b248e4067b3b364b014ab3056",
            "7499bf8146bd48648178031d5d256d06",
            "0eaffe86554b40dabfde2a2ce8a89582",
            "669df74295514a1e93aa3452c73b499f",
            "4545f94179df4e90bb9647b60ece1272"
          ]
        },
        "outputId": "40d5d2ca-fba8-4db4-dc27-15ff67113ea3"
      },
      "source": [
        "# Instantiate CamemBERT classifier model\n",
        "camembert_clf = CamemBERTClassifier()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a78cbb06ffd149e795524e6b38775279",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=445032417, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f14mz-vhsuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss and optimizer\n",
        "criterion = CrossEntropyLoss()\n",
        "opti = Adam(camembert_clf.parameters(), lr = 3e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZUQxW1biwti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, criterion, opti, train_loader, val_loader, max_eps=3, \n",
        "          gpu=True, print_every=100, validate_every=1):\n",
        "    \"\"\"Train a transformer model and compute loss on validation data.\"\"\"\n",
        "    if gpu:\n",
        "        model = model.to(\"cuda\")\n",
        "    # Unfreeze weights to allow fine tuning\n",
        "    model.train() \n",
        "\n",
        "    train_loss_total = 0\n",
        "    n_batch_train = 0\n",
        "    for ep in range(max_eps):\n",
        "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "            # Clear gradients (avoid accumulation)\n",
        "            opti.zero_grad()  \n",
        "            # Transfer tensors to GPU\n",
        "            if gpu:\n",
        "                seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "            # Compute logits\n",
        "            logits = model(seq, attn_masks)\n",
        "            # Compute batch loss\n",
        "            loss = criterion(logits, labels)\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            # Optimization step\n",
        "            opti.step()\n",
        "            # Accumulate train loss over batches\n",
        "            train_loss_total += loss.item()\n",
        "            n_batch_train += 1\n",
        "\n",
        "            # Compute average loss over the last `print_every` training batches\n",
        "            if print_every is not None and (it + 1) % print_every == 0:\n",
        "                print(f'Epoch {ep+1}, batch {it+1}. Average loss over last {print_every} training batches : {train_loss_total/n_batch_train}')\n",
        "                # Reinitialize accumulators\n",
        "                train_loss_total = 0\n",
        "                n_batch_train = 0\n",
        "\n",
        "        if validate_every is not None and ep % validate_every == 0:\n",
        "            # Evaluation on the validation set\n",
        "\n",
        "            predictions_val = []\n",
        "            true_labels_val = []\n",
        "            for it, (seq, attn_masks, labels) in enumerate(val_loader):\n",
        "                if gpu:\n",
        "                    seq, attn_masks = seq.cuda(), attn_masks.cuda()\n",
        "                # Compute logits without constructing the computing graph\n",
        "                # (only needed for backprop)\n",
        "                with torch.no_grad():\n",
        "                    logits_val = model(seq, attn_masks)\n",
        "                preds_batch = torch.argmax(logits_val, 1).cpu().numpy()\n",
        "                predictions_val.extend(preds_batch)\n",
        "                true_labels_val.extend(labels.numpy())\n",
        "\n",
        "            val_f1 = f1_score(true_labels_val, predictions_val, average='micro')\n",
        "            print('------------------------------------------------------------')\n",
        "            print(\"Epoch {} complete. F1 score on validation data : {}\".format(ep+1, val_f1))\n",
        "            print('------------------------------------------------------------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nfxNPWenHb-",
        "colab_type": "code",
        "outputId": "0639153d-f902-4405-9168-a0e39049ebb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "# Enforce deterministic behavior to ensure reproducibility of the results\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "train(camembert_clf, criterion, opti, train_loader, val_loader,\n",
        "      max_eps=1, gpu=True, print_every=500, validate_every=1)\n",
        "\n",
        "# Grid search (only 1 epoch each time, systematic overtraining above that) :\n",
        "# lr = 5e-5 => val_f1 = 0.49\n",
        "# lr = 3e-5 => val_f1 = 0.52"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, batch 500. Average loss over last 500 training batches : 1.5918752009868622\n",
            "Epoch 1, batch 1000. Average loss over last 500 training batches : 0.9780670761466026\n",
            "Epoch 1, batch 1500. Average loss over last 500 training batches : 0.7167568392157555\n",
            "Epoch 1, batch 2000. Average loss over last 500 training batches : 0.623441261216998\n",
            "Epoch 1, batch 2500. Average loss over last 500 training batches : 0.5532458843886853\n",
            "Epoch 1, batch 3000. Average loss over last 500 training batches : 0.4762355045974255\n",
            "Epoch 1, batch 3500. Average loss over last 500 training batches : 0.4380950675457716\n",
            "------------------------------------------------------------\n",
            "Epoch 1 complete. F1 score on validation data : 0.4647969960103262\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFNaQyUBKf6B",
        "colab_type": "text"
      },
      "source": [
        "# Final evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3i6rPwv2k-5",
        "colab_type": "text"
      },
      "source": [
        "### Quantitative evaluation: F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3tvHk02Kg4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TFIDF\n",
        "\n",
        "y_test_pred_tfidf = tfidf_pipeline.predict(X_test)\n",
        "test_score_tfidf = f1_score(y_test, y_test_pred_tfidf, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lLVo45ILnqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FastText\n",
        "\n",
        "y_test_pred_fasttext = fasttext_pipeline.predict(X_test)\n",
        "test_score_fasttext = f1_score(y_test, y_test_pred_fasttext, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxG0wUKGQ7PM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# doc2vec\n",
        "\n",
        "corpus_test_d2v = build_d2v_corpus(X_test, tokens_only=True)\n",
        "X_test_d2v = np.array([model.infer_vector(doc) for doc in corpus_test_d2v])\n",
        "y_test_pred_d2v = clf.predict(X_test_d2v)\n",
        "test_score_d2v = f1_score(y_test, y_test_pred_d2v, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTCCjA3yR0o0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CamemBERT\n",
        "\n",
        "# Create instance of test dataloader\n",
        "test_set = CorpusToTorchDataset(X_test, y_test, model_name=BERT_MODEL_NAME, maxlen=100)\n",
        "test_loader = DataLoader(test_set, batch_size = 12, num_workers = N_CORES)\n",
        "\n",
        "def eval(model, test_loader, gpu=True):\n",
        "    \"\"\"Compute predictions of a trained transforme model on test data.\"\"\"\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    for it, (seq, attn_masks, labels) in enumerate(test_loader):\n",
        "        if gpu:\n",
        "            seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "        # Compute logits without constructing the computing graph\n",
        "        # (only needed for backprop)\n",
        "        with torch.no_grad():\n",
        "            logits = model(seq, attn_masks)\n",
        "        # Compute predictions from logits and store them as arrays\n",
        "        preds_batch = torch.argmax(logits, 1).cpu().numpy()\n",
        "        predictions.extend(preds_batch)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "y_test_pred_camembert = eval(camembert_clf, test_loader)\n",
        "test_score_camembert = f1_score(y_test, y_test_pred_camembert, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7Xu42gIhQd_",
        "colab_type": "code",
        "outputId": "b9f5f13a-0020-4873-c717-10d42bb25460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "# Compare performances\n",
        "models = ['TF-IDF', 'FastText', 'Doc2Vec', 'CamemBERT']\n",
        "scores = [test_score_tfidf, test_score_fasttext, test_score_d2v, test_score_camembert]\n",
        "df_scores = pd.DataFrame(zip(models, scores), columns=['Model', 'F1 score'])\n",
        "df_scores.sort_values('F1 score', ascending=False)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>F1 score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CamemBERT</td>\n",
              "      <td>0.485862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TF-IDF</td>\n",
              "      <td>0.441159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>0.374399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FastText</td>\n",
              "      <td>0.340960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Model  F1 score\n",
              "3  CamemBERT  0.485862\n",
              "0     TF-IDF  0.441159\n",
              "2    Doc2Vec  0.374399\n",
              "1   FastText  0.340960"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k07PcLHf2JZC",
        "colab_type": "text"
      },
      "source": [
        "We find that CamemBERT has the highest F1 score. In order to make a qualitative evaluation of this model, we build the confusion matrix based on the predictions of CamemBERT on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR93044f2zXx",
        "colab_type": "text"
      },
      "source": [
        "### Qualitative evaluation: confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5A1NnxH2iei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_conf_matrix_df(y_true, y_pred):\n",
        "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
        "    conf_matrix = pd.DataFrame(conf_matrix, columns=list(le.classes_), index=list(le.classes_))\n",
        "    \n",
        "    row_percentages = []\n",
        "    for i in range(0,10):\n",
        "        perc = round(conf_matrix.iloc[i,i]/sum(conf_matrix.iloc[0:10,i]), 3)\n",
        "        row_percentages.append(perc)\n",
        "    \n",
        "    row_percentages = pd.DataFrame([row_percentages], columns=list(le.classes_))\n",
        "    \n",
        "    col_percentages = []\n",
        "    for i in range(0,10):\n",
        "        perc = round(conf_matrix.iloc[i,i]/sum(conf_matrix.iloc[i,0:10]), 3)\n",
        "        col_percentages.append(perc)\n",
        "    col_percentages.append(None)\n",
        "    \n",
        "    conf_matrix = conf_matrix.append(row_percentages)\n",
        "    conf_matrix = conf_matrix.rename(index={0: 'PRECISION'})\n",
        "    conf_matrix['RECALL'] = col_percentages\n",
        "\n",
        "    return(conf_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjEn9dSw3ww3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conf_matrix_BERT = get_conf_matrix_df(y_test, y_test_pred_camembert)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWROz_Hg3-qO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "d9da2c69-75ff-416d-9e5a-ffa482766da9"
      },
      "source": [
        "conf_matrix_BERT"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Balzac</th>\n",
              "      <th>Daudet</th>\n",
              "      <th>Dumas</th>\n",
              "      <th>Flaubert</th>\n",
              "      <th>Hugo</th>\n",
              "      <th>Maupassant</th>\n",
              "      <th>Stendhal</th>\n",
              "      <th>Verne</th>\n",
              "      <th>Vigny</th>\n",
              "      <th>Zola</th>\n",
              "      <th>RECALL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Balzac</th>\n",
              "      <td>202.000</td>\n",
              "      <td>33.000</td>\n",
              "      <td>68.000</td>\n",
              "      <td>36.000</td>\n",
              "      <td>24.000</td>\n",
              "      <td>13.000</td>\n",
              "      <td>392.00</td>\n",
              "      <td>258.000</td>\n",
              "      <td>34.000</td>\n",
              "      <td>10.000</td>\n",
              "      <td>0.189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daudet</th>\n",
              "      <td>0.000</td>\n",
              "      <td>63.000</td>\n",
              "      <td>27.000</td>\n",
              "      <td>55.000</td>\n",
              "      <td>19.000</td>\n",
              "      <td>31.000</td>\n",
              "      <td>4.00</td>\n",
              "      <td>149.000</td>\n",
              "      <td>5.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dumas</th>\n",
              "      <td>18.000</td>\n",
              "      <td>14.000</td>\n",
              "      <td>2008.000</td>\n",
              "      <td>49.000</td>\n",
              "      <td>61.000</td>\n",
              "      <td>32.000</td>\n",
              "      <td>50.00</td>\n",
              "      <td>19.000</td>\n",
              "      <td>53.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flaubert</th>\n",
              "      <td>3.000</td>\n",
              "      <td>8.000</td>\n",
              "      <td>14.000</td>\n",
              "      <td>506.000</td>\n",
              "      <td>23.000</td>\n",
              "      <td>46.000</td>\n",
              "      <td>13.00</td>\n",
              "      <td>5.000</td>\n",
              "      <td>6.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hugo</th>\n",
              "      <td>4.000</td>\n",
              "      <td>11.000</td>\n",
              "      <td>39.000</td>\n",
              "      <td>72.000</td>\n",
              "      <td>223.000</td>\n",
              "      <td>8.000</td>\n",
              "      <td>1050.00</td>\n",
              "      <td>47.000</td>\n",
              "      <td>97.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Maupassant</th>\n",
              "      <td>9.000</td>\n",
              "      <td>51.000</td>\n",
              "      <td>34.000</td>\n",
              "      <td>26.000</td>\n",
              "      <td>35.000</td>\n",
              "      <td>96.000</td>\n",
              "      <td>13.00</td>\n",
              "      <td>27.000</td>\n",
              "      <td>6.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stendhal</th>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>39.000</td>\n",
              "      <td>11.000</td>\n",
              "      <td>20.000</td>\n",
              "      <td>14.000</td>\n",
              "      <td>542.00</td>\n",
              "      <td>3.000</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Verne</th>\n",
              "      <td>0.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>62.000</td>\n",
              "      <td>21.000</td>\n",
              "      <td>21.000</td>\n",
              "      <td>5.000</td>\n",
              "      <td>10.00</td>\n",
              "      <td>290.000</td>\n",
              "      <td>8.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vigny</th>\n",
              "      <td>22.000</td>\n",
              "      <td>61.000</td>\n",
              "      <td>23.000</td>\n",
              "      <td>14.000</td>\n",
              "      <td>24.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>35.00</td>\n",
              "      <td>26.000</td>\n",
              "      <td>54.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Zola</th>\n",
              "      <td>61.000</td>\n",
              "      <td>83.000</td>\n",
              "      <td>236.000</td>\n",
              "      <td>150.000</td>\n",
              "      <td>31.000</td>\n",
              "      <td>84.000</td>\n",
              "      <td>58.00</td>\n",
              "      <td>92.000</td>\n",
              "      <td>52.000</td>\n",
              "      <td>157.000</td>\n",
              "      <td>0.156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRECISION</th>\n",
              "      <td>0.631</td>\n",
              "      <td>0.192</td>\n",
              "      <td>0.787</td>\n",
              "      <td>0.538</td>\n",
              "      <td>0.464</td>\n",
              "      <td>0.291</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.317</td>\n",
              "      <td>0.169</td>\n",
              "      <td>0.918</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Balzac  Daudet     Dumas  ...   Vigny     Zola  RECALL\n",
              "Balzac      202.000  33.000    68.000  ...  34.000   10.000   0.189\n",
              "Daudet        0.000  63.000    27.000  ...   5.000    1.000   0.178\n",
              "Dumas        18.000  14.000  2008.000  ...  53.000    0.000   0.872\n",
              "Flaubert      3.000   8.000    14.000  ...   6.000    0.000   0.811\n",
              "Hugo          4.000  11.000    39.000  ...  97.000    0.000   0.144\n",
              "Maupassant    9.000  51.000    34.000  ...   6.000    3.000   0.320\n",
              "Stendhal      1.000   1.000    39.000  ...   5.000    0.000   0.852\n",
              "Verne         0.000   3.000    62.000  ...   8.000    0.000   0.690\n",
              "Vigny        22.000  61.000    23.000  ...  54.000    0.000   0.208\n",
              "Zola         61.000  83.000   236.000  ...  52.000  157.000   0.156\n",
              "PRECISION     0.631   0.192     0.787  ...   0.169    0.918     NaN\n",
              "\n",
              "[11 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzBpN1Ht7dHs",
        "colab_type": "text"
      },
      "source": [
        "!! CONFUSION MATRIX A INTERPRETER !!"
      ]
    }
  ]
}