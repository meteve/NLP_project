{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of who_wrote_this.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "569c49e2da664426850ee855122ea291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c13df0b2fdb3401e9e1b5d587b5a0a02",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8c80dfdc2f074911af96027c99175989",
              "IPY_MODEL_94ea1cf39e514009945da7c228ae2825"
            ]
          }
        },
        "c13df0b2fdb3401e9e1b5d587b5a0a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c80dfdc2f074911af96027c99175989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_29fc88bd153243a199644b67861cded6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 637,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 637,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ead0301b10764559b32c00c125318a11"
          }
        },
        "94ea1cf39e514009945da7c228ae2825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d66fc710deee424eb982c10e879675fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 637/637 [00:19&lt;00:00, 32.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a380b9569ff649b3b1f497206a284628"
          }
        },
        "29fc88bd153243a199644b67861cded6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ead0301b10764559b32c00c125318a11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d66fc710deee424eb982c10e879675fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a380b9569ff649b3b1f497206a284628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22303ead9d5e4883bace42383561a4af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5f89f7f240a8454e861a3a03c92e07a4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2fdaf33beec5490b9d5e8116b9a4956d",
              "IPY_MODEL_dd5975c9567946deb588b3389062c755"
            ]
          }
        },
        "5f89f7f240a8454e861a3a03c92e07a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fdaf33beec5490b9d5e8116b9a4956d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69d07a73a8154e5fae3a50a7d390886c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 810912,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 810912,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_549184c47eb54b658f58d2dcb01413a6"
          }
        },
        "dd5975c9567946deb588b3389062c755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_095acced7e9946558abf6f1fb7f7e089",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 811k/811k [00:01&lt;00:00, 476kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72e0b7bba1a84f789f4ba7357c386e21"
          }
        },
        "69d07a73a8154e5fae3a50a7d390886c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "549184c47eb54b658f58d2dcb01413a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "095acced7e9946558abf6f1fb7f7e089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72e0b7bba1a84f789f4ba7357c386e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c945fb32dfe4013ab24ffbe5df1d065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d9e22ac726f5486baee2fb87a9af7cff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9960530dd8b14967ab140b031ffca911",
              "IPY_MODEL_b0a4ce006fe14a9f85d1997e8befc5c5"
            ]
          }
        },
        "d9e22ac726f5486baee2fb87a9af7cff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9960530dd8b14967ab140b031ffca911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cff09b99358f43b0986812d057ac243f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 445032417,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445032417,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21c067ee71154558a00d2860f3eb0932"
          }
        },
        "b0a4ce006fe14a9f85d1997e8befc5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0bdc03cb56a40bcb03d8025de7d2dac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:14&lt;00:00, 31.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2bf7858d9207409fb558277389e67930"
          }
        },
        "cff09b99358f43b0986812d057ac243f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21c067ee71154558a00d2860f3eb0932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0bdc03cb56a40bcb03d8025de7d2dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2bf7858d9207409fb558277389e67930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw6VsDhUun5n",
        "colab_type": "text"
      },
      "source": [
        "# Who wrote this : a framework for French novelist identification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rR8SIQ_ks-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "449d99ee-f284-41c9-deec-097b41e8292d"
      },
      "source": [
        "# Download necessary additional libraries\n",
        "!pip install unidecode\n",
        "!pip install transformers\n",
        "!python -m spacy download fr_core_news_md"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 23.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 4.9MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 25.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.31)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.31)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=94fbda5a0d6d3693bd3a3085a41a23b5c00196457ac49725378589a3be2d90a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.7.0\n",
            "Collecting fr_core_news_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-2.2.5/fr_core_news_md-2.2.5.tar.gz (88.6MB)\n",
            "\u001b[K     |████████████████████████████████| 88.6MB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.18.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (46.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (2.8)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: fr-core-news-md\n",
            "  Building wheel for fr-core-news-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-md: filename=fr_core_news_md-2.2.5-cp36-none-any.whl size=90338488 sha256=1a6870a4d0a4c3390cf3a3744f8b11cd2c3bc07e74406b40ae21c9a64e95b26f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ljo9myu2/wheels/c6/18/b6/f628642acc7872a53cf81269dd1c394d96da69564ccfac5425\n",
            "Successfully built fr-core-news-md\n",
            "Installing collected packages: fr-core-news-md\n",
            "Successfully installed fr-core-news-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liRJXYg6Cv2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "import unidecode\n",
        "import urllib.request\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "import spacy\n",
        "import fr_core_news_md\n",
        "import gensim\n",
        "from gensim.models import Doc2Vec, FastText\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUk_HtdMolVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of available cores for parallel computing\n",
        "N_CORES = cpu_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPykVwoCzxbu",
        "colab_type": "text"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is9UbtTqWa9L",
        "colab_type": "code",
        "outputId": "10b01686-1263-4bfc-a525-3ce27595b02b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "# Download data from the GitHub repository\n",
        "!wget https://raw.githubusercontent.com/meteve/NLP_project/master/data/corpus_train.csv\n",
        "!wget https://raw.githubusercontent.com/meteve/NLP_project/master/data/corpus_test.csv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-01 08:25:24--  https://raw.githubusercontent.com/meteve/NLP_project/master/data/corpus_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18165744 (17M) [text/plain]\n",
            "Saving to: ‘corpus_train.csv’\n",
            "\n",
            "\rcorpus_train.csv      0%[                    ]       0  --.-KB/s               \rcorpus_train.csv    100%[===================>]  17.32M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-04-01 08:25:24 (164 MB/s) - ‘corpus_train.csv’ saved [18165744/18165744]\n",
            "\n",
            "--2020-04-01 08:25:26--  https://raw.githubusercontent.com/meteve/NLP_project/master/data/corpus_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6894810 (6.6M) [text/plain]\n",
            "Saving to: ‘corpus_test.csv’\n",
            "\n",
            "corpus_test.csv     100%[===================>]   6.58M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-04-01 08:25:26 (91.7 MB/s) - ‘corpus_test.csv’ saved [6894810/6894810]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i0eCW7-DDDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import train data\n",
        "train_df = pd.read_csv('corpus_train.csv', sep='|')\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True) # Shuffle\n",
        "X_train = train_df['paragraph'].values\n",
        "y_labels_train = train_df['author'].values\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_labels_train)\n",
        "N_CLASSES = len(np.unique(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPnN3eBy3slZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import test data and build validation dataset\n",
        "test_df = pd.read_csv('corpus_test.csv', sep='|')\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True) # Shuffle\n",
        "X_val, X_test, y_val, y_test = train_test_split(test_df['paragraph'].values,\n",
        "                                                test_df['author'].values,\n",
        "                                                test_size=0.5, random_state=42)\n",
        "y_val = le.transform(y_val)\n",
        "y_test = le.transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk7Dfp3JKzTj",
        "colab_type": "code",
        "outputId": "561247d4-588f-41c2-e28b-7dd137ad8683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train_df.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paragraph</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>--Ah parbleu! parce que vos ambassadeurs, vos ...</td>\n",
              "      <td>Dumas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ce qu'il y avait de plus pressé, c'était d'enl...</td>\n",
              "      <td>Dumas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Puis il se mit à jouer. Il eut un moment ravis...</td>\n",
              "      <td>Hugo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>--Est-il vrai, ma tante, dit la jeune Martine ...</td>\n",
              "      <td>Vigny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Le fiacre roulait le long des arbres des Champ...</td>\n",
              "      <td>Hugo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           paragraph author\n",
              "0  --Ah parbleu! parce que vos ambassadeurs, vos ...  Dumas\n",
              "1  Ce qu'il y avait de plus pressé, c'était d'enl...  Dumas\n",
              "2  Puis il se mit à jouer. Il eut un moment ravis...   Hugo\n",
              "3  --Est-il vrai, ma tante, dit la jeune Martine ...  Vigny\n",
              "4  Le fiacre roulait le long des arbres des Champ...   Hugo"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pc4i1aPKJqv",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSOiEE20z1o4",
        "colab_type": "text"
      },
      "source": [
        "### Baseline : TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENoBUodrpxwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "URL = 'https://raw.githubusercontent.com/stopwords-iso/stopwords-fr/master/stopwords-fr.txt'\n",
        "response = urllib.request.urlopen(URL)\n",
        "stopwords = response.read().decode('utf-8').splitlines()\n",
        "stopwords = [unidecode.unidecode(x) for x in stopwords]\n",
        "stopwords.append('quelqu') # Make stopwords consistent with scikit tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOwk-ES44rEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ML pipeline : TF-IDF + SVM classifier\n",
        "\n",
        "tfidf_vecto = TfidfVectorizer(stop_words=stopwords)\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "\n",
        "tfidf_pipeline = Pipeline([\n",
        "                           ('tf-idf', tfidf_vecto),\n",
        "                           ('clf', clf)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KlP_Iw2oth4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keep sklearn preprocessing pipeline for later\n",
        "preprocessor = tfidf_vecto.build_analyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ML1EXEK2kA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing + training\n",
        "tfidf_pipeline = tfidf_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdyNC-ok3qxy",
        "colab_type": "code",
        "outputId": "afe99558-8881-4ef1-b967-7d589e44b9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute predictions and validation score\n",
        "y_val_pred_tfidf = tfidf_pipeline.predict(X_val)\n",
        "tfidf_val_score = f1_score(y_val, y_val_pred_tfidf, average='micro')\n",
        "print('F1 score on validation set with TF-IDF :', \n",
        "      tfidf_val_score.round(2))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set with TF-IDF : 0.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSb0A41gsP8z",
        "colab_type": "code",
        "outputId": "be4ad830-739e-402e-a30c-345861698a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute predictions and score on train set\n",
        "y_train_pred_tfidf = tfidf_pipeline.predict(X_train)\n",
        "tfidf_train_score = f1_score(y_train, y_train_pred_tfidf, average='micro')\n",
        "print('F1 score on train set with TF-IDF :', \n",
        "      tfidf_train_score.round(2))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on train set with TF-IDF : 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpFzXyGUsN9L",
        "colab_type": "text"
      },
      "source": [
        "The very high gap between train and validation scores indicate that the baseline overfits the training data. It may be due to the fact that there are different books in the train and test sets. Some locations and characters which are present in the books of the training set may have a strong influence on the training of the model. To verify this, we compute tf-idf weights for the well classified paragraphs of the train set, and look at the most important words for each author in terms of tf-idf weights.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8P2kyv1sSKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top_tfidf_feats(row, features, top_n):\n",
        "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
        "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
        "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
        "    df = pd.DataFrame(top_feats)\n",
        "    df.columns = ['feature', 'tfidf']\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KINbMCHcsU4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tfidf_weights_by_author(author, NER=False, top_n=20):\n",
        "    '''Return words with high tfidf weights, for well-classified paragraphs of an author with or without NER'''\n",
        "    y_true = y_train\n",
        "    \n",
        "    if NER == True:\n",
        "        y_pred = y_train_pred_tfidf_ner\n",
        "        pipe = tfidf_pipeline_ner\n",
        "        X = X_train_ner\n",
        "    else:\n",
        "        y_pred = y_train_pred_tfidf\n",
        "        pipe = tfidf_pipeline\n",
        "        X = X_train\n",
        "        \n",
        "    \n",
        "    if type(author) == str:\n",
        "        author_index = list(le.classes_).index(author)\n",
        "    elif type(author) == int:\n",
        "        author_index = author\n",
        "   \n",
        "    # keep well classified paragraphs of the auhtor\n",
        "    well_classif_indexes = ((y_true == author_index) & (y_pred == author_index))\n",
        "    X_train_well_classif = X[well_classif_indexes]\n",
        "    \n",
        "    # get tf-idf vectors\n",
        "    vec = tfidf_pipeline.named_steps['tf-idf']\n",
        "    Xtr = vec.transform(X_train_well_classif)\n",
        "    features = vec.get_feature_names()\n",
        "    \n",
        "    # get mean tf-idf scores\n",
        "    D = Xtr.toarray()\n",
        "    tfidf_means = np.mean(D, axis=0)\n",
        "    \n",
        "    return top_tfidf_feats(tfidf_means, features, top_n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbmVlzZtyGRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tfidf_weights_by_author(author, y_true, y_pred, X, top_n=20):\n",
        "    '''Return words with high tfidf weights, for well-classified paragraphs of an author with or without NER'''        \n",
        "    \n",
        "    if type(author) == str:\n",
        "        author_index = list(le.classes_).index(author)\n",
        "    elif type(author) == int:\n",
        "        author_index = author\n",
        "   \n",
        "    # keep well classified paragraphs of the auhtor\n",
        "    well_classif_indexes = ((y_true == author_index) & (y_pred == author_index))\n",
        "    X_train_well_classif = X[well_classif_indexes]\n",
        "    \n",
        "    # get tf-idf vectors\n",
        "    vec = tfidf_pipeline.named_steps['tf-idf']\n",
        "    Xtr = vec.transform(X_train_well_classif)\n",
        "    features = vec.get_feature_names()\n",
        "    \n",
        "    # get mean tf-idf scores\n",
        "    D = Xtr.toarray()\n",
        "    tfidf_means = np.mean(D, axis=0)\n",
        "    \n",
        "    return top_tfidf_feats(tfidf_means, features, top_n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PoT5OE3sWrw",
        "colab_type": "code",
        "outputId": "4a6ae80b-b06f-47bd-9941-33939147dcbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "get_tfidf_weights_by_author(author='Maupassant', y_true=y_train, y_pred=y_train_pred_tfidf, X=X_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jeanne</td>\n",
              "      <td>0.020320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>duroy</td>\n",
              "      <td>0.016129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>était</td>\n",
              "      <td>0.013896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>femme</td>\n",
              "      <td>0.011180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>forestier</td>\n",
              "      <td>0.010246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>walter</td>\n",
              "      <td>0.010040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ça</td>\n",
              "      <td>0.009915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>point</td>\n",
              "      <td>0.009565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>là</td>\n",
              "      <td>0.008472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>où</td>\n",
              "      <td>0.008278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bras</td>\n",
              "      <td>0.007982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>faire</td>\n",
              "      <td>0.007716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>georges</td>\n",
              "      <td>0.007691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>temps</td>\n",
              "      <td>0.007631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>mère</td>\n",
              "      <td>0.007386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>petite</td>\n",
              "      <td>0.007347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>même</td>\n",
              "      <td>0.007153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>mme</td>\n",
              "      <td>0.007131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>semblait</td>\n",
              "      <td>0.007093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>allait</td>\n",
              "      <td>0.007053</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      feature     tfidf\n",
              "0      jeanne  0.020320\n",
              "1       duroy  0.016129\n",
              "2       était  0.013896\n",
              "3       femme  0.011180\n",
              "4   forestier  0.010246\n",
              "5      walter  0.010040\n",
              "6          ça  0.009915\n",
              "7       point  0.009565\n",
              "8          là  0.008472\n",
              "9          où  0.008278\n",
              "10       bras  0.007982\n",
              "11      faire  0.007716\n",
              "12    georges  0.007691\n",
              "13      temps  0.007631\n",
              "14       mère  0.007386\n",
              "15     petite  0.007347\n",
              "16       même  0.007153\n",
              "17        mme  0.007131\n",
              "18   semblait  0.007093\n",
              "19     allait  0.007053"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMlOaXrXtC0r",
        "colab_type": "text"
      },
      "source": [
        "A relatively high number of proper nouns have a high tf-idf weight in the previous model. Next, we try to remove them using Named Entity Recognition (NER) procedure in order to evaluate whether it reduces overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfwlFsgYw8Rf",
        "colab_type": "text"
      },
      "source": [
        "### NER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdaBYrY1xGKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = fr_core_news_md.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LThQ2jrSx7Lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_named_entities(paragraph): \n",
        "  \"\"\"remove the named entities from a paragraph\"\"\"\n",
        "  doc = nlp(paragraph)\n",
        "  names = []\n",
        "  for ent in doc.ents:\n",
        "      # list of all the named entities recognized in the paragraph\n",
        "      names.append(ent)\n",
        "  # keep unique elements and convert to string    \n",
        "  names = set([str(x) for x in names])\n",
        "    \n",
        "  # remove named entities from the paragraph\n",
        "  paragraph_no_names = paragraph\n",
        "  for name in names:\n",
        "      paragraph_no_names = paragraph_no_names.replace(name, '')\n",
        "        \n",
        "  return paragraph_no_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ers1YsXS8a7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_ner = []\n",
        "\n",
        "for i, par in enumerate(X_train):\n",
        "  par_ner = remove_named_entities(par)\n",
        "  X_train_ner.append(par_ner)\n",
        "\n",
        "X_train_ner = np.array(X_train_ner)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er_AgKU6shFV",
        "colab_type": "code",
        "outputId": "6806d5ad-ca0f-4734-f14f-6f288f499201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "# Verify that proper nouns removal works\n",
        "_ = tfidf_pipeline.fit(X_train_ner, y_train)\n",
        "y_train_pred_tfidf_ner = tfidf_pipeline.predict(X_train_ner)\n",
        "get_tfidf_weights_by_author(author='Maupassant', y_true=y_train, y_pred=y_train_pred_tfidf_ner, X=X_train_ner)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>était</td>\n",
              "      <td>0.012927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>femme</td>\n",
              "      <td>0.010957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>point</td>\n",
              "      <td>0.010555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>là</td>\n",
              "      <td>0.008805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>baron</td>\n",
              "      <td>0.008727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>mère</td>\n",
              "      <td>0.008721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bras</td>\n",
              "      <td>0.008718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>où</td>\n",
              "      <td>0.008603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>semblait</td>\n",
              "      <td>0.008376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>petite</td>\n",
              "      <td>0.007993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>allait</td>\n",
              "      <td>0.007866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>mit</td>\n",
              "      <td>0.007597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>coup</td>\n",
              "      <td>0.007500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>temps</td>\n",
              "      <td>0.007120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>faire</td>\n",
              "      <td>0.007087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>mains</td>\n",
              "      <td>0.007086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>tête</td>\n",
              "      <td>0.007040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>même</td>\n",
              "      <td>0.007011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>yeux</td>\n",
              "      <td>0.006906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>sentait</td>\n",
              "      <td>0.006867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature     tfidf\n",
              "0      était  0.012927\n",
              "1      femme  0.010957\n",
              "2      point  0.010555\n",
              "3         là  0.008805\n",
              "4      baron  0.008727\n",
              "5       mère  0.008721\n",
              "6       bras  0.008718\n",
              "7         où  0.008603\n",
              "8   semblait  0.008376\n",
              "9     petite  0.007993\n",
              "10    allait  0.007866\n",
              "11       mit  0.007597\n",
              "12      coup  0.007500\n",
              "13     temps  0.007120\n",
              "14     faire  0.007087\n",
              "15     mains  0.007086\n",
              "16      tête  0.007040\n",
              "17      même  0.007011\n",
              "18      yeux  0.006906\n",
              "19   sentait  0.006867"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r9ftlb6xQCm",
        "colab_type": "code",
        "outputId": "e8796af0-dab3-4240-b92a-74b5fdf3466d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute score on train set AFTER proper nouns removal procedure\n",
        "tfidf_train_score_ner = f1_score(y_train, y_train_pred_tfidf_ner, average='micro')\n",
        "print('F1 score on train set with TF-IDF after proper nouns removal:', \n",
        "      tfidf_train_score_ner.round(2))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on train set with TF-IDF after proper nouns removal: 0.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0KOE89q4U90",
        "colab_type": "text"
      },
      "source": [
        "The train score is much lower after removing the proper nouns in the paragraphs. The overfitting was partially due to the presence of such proper nouns. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XButdewn9e0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val_ner = []\n",
        "\n",
        "for i, par in enumerate(X_val):\n",
        "  par_ner = remove_named_entities(par)\n",
        "  X_val_ner.append(par_ner)\n",
        "\n",
        "X_val_ner = np.array(X_val_ner)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXg9qpvp788m",
        "colab_type": "code",
        "outputId": "51ba0caf-65f2-4381-9694-70c37f84aa7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute predictions and validation score AFTER proper nouns removal procedure\n",
        "y_val_pred_tfidf_ner = tfidf_pipeline.predict(X_val_ner)\n",
        "tfidf_val_score_ner = f1_score(y_val, y_val_pred_tfidf_ner, average='micro')\n",
        "print('F1 score on validation set with TF-IDF after proper nouns removal:', \n",
        "      tfidf_val_score_ner.round(2))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set with TF-IDF after proper nouns removal: 0.42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOLRUrFLuSrP",
        "colab_type": "text"
      },
      "source": [
        "The validation score is also reduced when we remove the proper nouns of the paragraphs. This suggests that some names may appear in different books of the same author, and can actually be helpful for the predictions. Thus, we decide to keep proper nouns to train the other models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g88tOQuBz792",
        "colab_type": "text"
      },
      "source": [
        "### FastText (averaging of pre-trained word vectors)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9E444_cXwAy",
        "colab_type": "code",
        "outputId": "6fcc24e0-157b-462b-e6e7-55aa9f13e1b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# Download and extract FastText French word vectors\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz\n",
        "!gunzip cc.fr.300.bin.gz"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-01 08:44:07--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 2606:4700:10::6816:4a8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4496886212 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.fr.300.bin.gz’\n",
            "\n",
            "cc.fr.300.bin.gz    100%[===================>]   4.19G  39.5MB/s    in 2m 7s   \n",
            "\n",
            "2020-04-01 08:46:14 (33.9 MB/s) - ‘cc.fr.300.bin.gz’ saved [4496886212/4496886212]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAYXl07XADFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Fasttext French word vectors\n",
        "fasttext = FastText.load_fasttext_format('cc.fr.300.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r151opCRr8B1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_wv_fasttext(text):\n",
        "    \"\"\"Compute average of FastText's word vectors for a given text.\"\"\"\n",
        "    if text:\n",
        "        tokens = preprocessor(text)\n",
        "        wv_mat = np.zeros((len(tokens), fasttext.vector_size))\n",
        "        for i, tok in enumerate(tokens):\n",
        "            try:\n",
        "                wv_mat[i] = fasttext.wv[tok]\n",
        "            except KeyError:\n",
        "                pass\n",
        "        text_vec = wv_mat.mean(axis=0)\n",
        "    else:\n",
        "        text_vec = np.zeros(fasttext.vector_size)\n",
        "    return text_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRfHhI-LuzPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_corpus_fasttext(corpus):\n",
        "    \"\"\"Parallelize preprocessing and document vectors computation.\"\"\"\n",
        "    with Pool(N_CORES) as p:\n",
        "        corpus_prepro = p.map(text_to_wv_fasttext, list(corpus))\n",
        "    return np.array(corpus_prepro)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV7aqaByn1B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextToWV(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Enable to use preprocessing function in a sklearn pipeline.\"\"\"\n",
        "    def __init__(self, preprocessor):\n",
        "        self.preprocessor = preprocessor\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return(self)\n",
        "\n",
        "    def transform(self, X):\n",
        "        return self.preprocessor(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sg3YBbgJ0ZPm",
        "colab": {}
      },
      "source": [
        "# Prediction pipeline\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "fasttext_pipeline = Pipeline([\n",
        "                              ('fasttext_average', TextToWV(preprocess_corpus_fasttext)),\n",
        "                              ('clf', clf)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTvo5xwMob3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing + training\n",
        "fasttext_pipeline = fasttext_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIVGLvOm0pY_",
        "colab_type": "code",
        "outputId": "9d6f2a98-98fe-45a3-bd47-e47a8e0be288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute predictions and test score\n",
        "y_val_pred_fasttext = fasttext_pipeline.predict(X_val)\n",
        "val_score_fasttext = f1_score(y_val, y_val_pred_fasttext, average='micro')\n",
        "print('F1 score on validation set :',\n",
        "      val_score_fasttext.round(2))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set : 0.33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL0DTOLbvYq1",
        "colab_type": "text"
      },
      "source": [
        "### Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztQM6FneveCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_d2v_corpus(corpus, tokens_only=False):\n",
        "    \"\"\"Tokenize and build corpus as expected by Gensim Doc2Vec class.\"\"\"\n",
        "    corpus_tokenized = []\n",
        "    for i, text in enumerate(corpus):\n",
        "        tokens = preprocessor(text)\n",
        "        if tokens_only:\n",
        "            corpus_tokenized.append(tokens)\n",
        "        else:\n",
        "            corpus_tokenized.append(TaggedDocument(tokens, [i]))\n",
        "    return corpus_tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krsC1SYh5ACx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Format train and validation corpus as required by Doc2Vec\n",
        "corpus_train_d2v = build_d2v_corpus(X_train, tokens_only=False)\n",
        "corpus_val_d2v = build_d2v_corpus(X_val, tokens_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryhxTy1C5wwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Doc2Vec model\n",
        "model = Doc2Vec(vector_size=50, min_count=2, epochs=10, workers=N_CORES)\n",
        "model.build_vocab(corpus_train_d2v)\n",
        "model.train(corpus_train_d2v, total_examples=model.corpus_count, \n",
        "            epochs=model.epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pLoVbMK8_DI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute document vectors on train and validation sets\n",
        "X_train_d2v = np.array([model.infer_vector(doc.words) for doc in corpus_train_d2v])\n",
        "X_val_d2v = np.array([model.infer_vector(doc) for doc in corpus_val_d2v])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe3LTThCAICg",
        "colab_type": "code",
        "outputId": "01e6603d-afd0-4d9a-e106-453ff903aaeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute predictions and validation score\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "clf.fit(X_train_d2v, y_train)\n",
        "y_val_pred_d2v = clf.predict(X_val_d2v)\n",
        "val_score_d2v = f1_score(y_val, y_val_pred_d2v, average='micro')\n",
        "print('F1 score on validation set :', \n",
        "      val_score_d2v.round(2))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on validation set : 0.37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUqdN5M90AQV",
        "colab_type": "text"
      },
      "source": [
        "### CamemBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6W9sKtFRXbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CorpusToTorchDataset(Dataset):\n",
        "    \"\"\"Convert corpus to tensors of token indices in CamemBERT vocabulary.\"\"\"\n",
        "    def __init__(self, corpus, labels, model_name, maxlen=100):\n",
        "        self.corpus = corpus\n",
        "        self.labels = labels\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.corpus)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # Select instance\n",
        "        sentence = self.corpus[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        # Preprocess data as required by BERT models\n",
        "        tokens = self.tokenizer.tokenize(sentence)\n",
        "        bos_token = self.tokenizer.cls_token\n",
        "        eos_token = self.tokenizer.sep_token\n",
        "        pad_token = self.tokenizer.pad_token\n",
        "        # Insert CLS and SEP tokens at beginning and end of sentence\n",
        "        tokens = [bos_token] + tokens + [eos_token]\n",
        "        if len(tokens) < self.maxlen:\n",
        "            # If sentence is shorter than maxlen, pad sentence using special \n",
        "            # padding token\n",
        "            tokens = tokens + [pad_token for _ in range(self.maxlen - len(tokens))]\n",
        "        else:\n",
        "            # Cut the sentence if it is longer than maxlen\n",
        "            tokens = tokens[:self.maxlen-1] + [eos_token]\n",
        "\n",
        "        # Convert tokens to tensor of indices in CamemBERT vocabulary\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
        "        # Get attention mask to distinguish padding tokens from actual tokens\n",
        "        pad_token_id = self.tokenizer.convert_tokens_to_ids(pad_token)\n",
        "        attn_mask = (tokens_ids_tensor != pad_token_id).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDnF51VmVtHG",
        "colab_type": "code",
        "outputId": "feee15cd-9189-4d6f-926a-9865cd9de1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "569c49e2da664426850ee855122ea291",
            "c13df0b2fdb3401e9e1b5d587b5a0a02",
            "8c80dfdc2f074911af96027c99175989",
            "94ea1cf39e514009945da7c228ae2825",
            "29fc88bd153243a199644b67861cded6",
            "ead0301b10764559b32c00c125318a11",
            "d66fc710deee424eb982c10e879675fd",
            "a380b9569ff649b3b1f497206a284628",
            "22303ead9d5e4883bace42383561a4af",
            "5f89f7f240a8454e861a3a03c92e07a4",
            "2fdaf33beec5490b9d5e8116b9a4956d",
            "dd5975c9567946deb588b3389062c755",
            "69d07a73a8154e5fae3a50a7d390886c",
            "549184c47eb54b658f58d2dcb01413a6",
            "095acced7e9946558abf6f1fb7f7e089",
            "72e0b7bba1a84f789f4ba7357c386e21"
          ]
        }
      },
      "source": [
        "# Create instances of training and validation dataloaders\n",
        "\n",
        "BERT_MODEL_NAME = 'camembert-base'\n",
        "MAXLEN = 100\n",
        "BATCH_SIZE = 12\n",
        "\n",
        "train_set = CorpusToTorchDataset(X_train, y_train, model_name=BERT_MODEL_NAME, maxlen=MAXLEN)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=N_CORES)\n",
        "\n",
        "val_set = CorpusToTorchDataset(X_val, y_val, model_name=BERT_MODEL_NAME, maxlen=MAXLEN)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=N_CORES)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "569c49e2da664426850ee855122ea291",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=637, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22303ead9d5e4883bace42383561a4af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=810912, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ydN8F8gOUI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CamemBERTClassifier(nn.Module):\n",
        "    \"\"\"Perform fine-tuning and classification using CamemBERT.\"\"\"\n",
        "    def __init__(self, pretrained_model_name=BERT_MODEL_NAME):\n",
        "        super(CamemBERTClassifier, self).__init__()\n",
        "        # Load CamemBERT\n",
        "        self.encoder = AutoModel.from_pretrained(pretrained_model_name)\n",
        "        # Add an extra dense layer to perform classification\n",
        "        self.cls_layer = nn.Linear(self.encoder.pooler.dense.out_features, N_CLASSES)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        # Feed input to BERT model to obtain contextualized representations\n",
        "        cont_reps, _ = self.encoder(seq, attention_mask=attn_masks)\n",
        "        # Get representation of [CLS] head\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "        # Feed document representation to the classifying layer\n",
        "        logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4A_4QjGOUP6",
        "colab_type": "code",
        "outputId": "1964d817-e0bb-4fb7-ee29-a4d3a904b9d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "5c945fb32dfe4013ab24ffbe5df1d065",
            "d9e22ac726f5486baee2fb87a9af7cff",
            "9960530dd8b14967ab140b031ffca911",
            "b0a4ce006fe14a9f85d1997e8befc5c5",
            "cff09b99358f43b0986812d057ac243f",
            "21c067ee71154558a00d2860f3eb0932",
            "a0bdc03cb56a40bcb03d8025de7d2dac",
            "2bf7858d9207409fb558277389e67930"
          ]
        }
      },
      "source": [
        "# Instantiate CamemBERT classifier model\n",
        "camembert_clf = CamemBERTClassifier()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c945fb32dfe4013ab24ffbe5df1d065",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=445032417, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f14mz-vhsuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss and optimizer\n",
        "criterion = CrossEntropyLoss()\n",
        "opti = Adam(camembert_clf.parameters(), lr=3e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZUQxW1biwti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, criterion, opti, train_loader, val_loader, max_eps=3, \n",
        "          gpu=True, print_every=100, validate_every=1):\n",
        "    \"\"\"Train a transformer model and compute loss on validation data.\"\"\"\n",
        "    if gpu:\n",
        "        model = model.to(\"cuda\")\n",
        "    # Unfreeze weights to allow fine tuning\n",
        "    model.train() \n",
        "\n",
        "    train_loss_total = 0\n",
        "    n_batch_train = 0\n",
        "    for ep in range(max_eps):\n",
        "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "            # Clear gradients (avoid accumulation)\n",
        "            opti.zero_grad()  \n",
        "            # Transfer tensors to GPU\n",
        "            if gpu:\n",
        "                seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "            # Compute logits\n",
        "            logits = model(seq, attn_masks)\n",
        "            # Compute batch loss\n",
        "            loss = criterion(logits, labels)\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            # Optimization step\n",
        "            opti.step()\n",
        "            # Accumulate train loss over batches\n",
        "            train_loss_total += loss.item()\n",
        "            n_batch_train += 1\n",
        "\n",
        "            # Compute average loss over the last `print_every` training batches\n",
        "            if print_every is not None and (it + 1) % print_every == 0:\n",
        "                print(f'Epoch {ep+1}, batch {it+1}. Average loss over last {print_every} training batches : {train_loss_total/n_batch_train}')\n",
        "                # Reinitialize accumulators\n",
        "                train_loss_total = 0\n",
        "                n_batch_train = 0\n",
        "\n",
        "        if validate_every is not None and ep % validate_every == 0:\n",
        "            # Evaluation on the validation set\n",
        "\n",
        "            predictions_val = []\n",
        "            true_labels_val = []\n",
        "            for it, (seq, attn_masks, labels) in enumerate(val_loader):\n",
        "                if gpu:\n",
        "                    seq, attn_masks = seq.cuda(), attn_masks.cuda()\n",
        "                # Compute logits without constructing the computing graph\n",
        "                # (only needed for backprop)\n",
        "                with torch.no_grad():\n",
        "                    logits_val = model(seq, attn_masks)\n",
        "                preds_batch = torch.argmax(logits_val, 1).cpu().numpy()\n",
        "                predictions_val.extend(preds_batch)\n",
        "                true_labels_val.extend(labels.numpy())\n",
        "\n",
        "            val_f1 = f1_score(true_labels_val, predictions_val, average='micro')\n",
        "            print('------------------------------------------------------------')\n",
        "            print(\"Epoch {} complete. F1 score on validation data : {}\".format(ep+1, val_f1))\n",
        "            print('------------------------------------------------------------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nfxNPWenHb-",
        "colab_type": "code",
        "outputId": "ef3817a3-6661-4c94-85e3-045bdad4dca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Train CamemBERT\n",
        "train(camembert_clf, criterion, opti, train_loader, val_loader,\n",
        "      max_eps=1, # Systematic overtraining after 1 epoch which degrades results\n",
        "      gpu=True, \n",
        "      print_every=500, validate_every=1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, batch 500. Average loss over last 500 training batches : 1.6024817779064178\n",
            "Epoch 1, batch 1000. Average loss over last 500 training batches : 0.979894129216671\n",
            "Epoch 1, batch 1500. Average loss over last 500 training batches : 0.7141468065679073\n",
            "Epoch 1, batch 2000. Average loss over last 500 training batches : 0.5915717537403107\n",
            "Epoch 1, batch 2500. Average loss over last 500 training batches : 0.517938755877316\n",
            "Epoch 1, batch 3000. Average loss over last 500 training batches : 0.468482445307076\n",
            "Epoch 1, batch 3500. Average loss over last 500 training batches : 0.4357746082171798\n",
            "------------------------------------------------------------\n",
            "Epoch 1 complete. F1 score on validation data : 0.4962450129077681\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFNaQyUBKf6B",
        "colab_type": "text"
      },
      "source": [
        "# Final evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3i6rPwv2k-5",
        "colab_type": "text"
      },
      "source": [
        "### Quantitative evaluation: F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3tvHk02Kg4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TFIDF\n",
        "\n",
        "y_test_pred_tfidf = tfidf_pipeline.predict(X_test)\n",
        "test_score_tfidf = f1_score(y_test, y_test_pred_tfidf, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lLVo45ILnqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FastText\n",
        "\n",
        "y_test_pred_fasttext = fasttext_pipeline.predict(X_test)\n",
        "test_score_fasttext = f1_score(y_test, y_test_pred_fasttext, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxG0wUKGQ7PM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# doc2vec\n",
        "\n",
        "corpus_test_d2v = build_d2v_corpus(X_test, tokens_only=True)\n",
        "X_test_d2v = np.array([model.infer_vector(doc) for doc in corpus_test_d2v])\n",
        "y_test_pred_d2v = clf.predict(X_test_d2v)\n",
        "test_score_d2v = f1_score(y_test, y_test_pred_d2v, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTCCjA3yR0o0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CamemBERT\n",
        "\n",
        "# Create instance of test dataloader\n",
        "test_set = CorpusToTorchDataset(X_test, y_test, model_name=BERT_MODEL_NAME, maxlen=MAXLEN)\n",
        "test_loader = DataLoader(test_set, batch_size=12, num_workers=N_CORES)\n",
        "\n",
        "def eval(model, test_loader, gpu=True):\n",
        "    \"\"\"Compute predictions of a trained transforme model on test data.\"\"\"\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    for it, (seq, attn_masks, labels) in enumerate(test_loader):\n",
        "        if gpu:\n",
        "            seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "        # Compute logits without constructing the computing graph\n",
        "        # (only needed for backprop)\n",
        "        with torch.no_grad():\n",
        "            logits = model(seq, attn_masks)\n",
        "        # Compute predictions from logits and store them as arrays\n",
        "        preds_batch = torch.argmax(logits, 1).cpu().numpy()\n",
        "        predictions.extend(preds_batch)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "y_test_pred_camembert = eval(camembert_clf, test_loader)\n",
        "test_score_camembert = f1_score(y_test, y_test_pred_camembert, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7Xu42gIhQd_",
        "colab_type": "code",
        "outputId": "811458bd-fb96-47d5-e70c-43c53dd96171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "# Compare performances\n",
        "models = ['TF-IDF', 'FastText', 'Doc2Vec', 'CamemBERT']\n",
        "scores = [test_score_tfidf, test_score_fasttext, test_score_d2v, test_score_camembert]\n",
        "df_scores = pd.DataFrame(zip(models, scores), columns=['Model', 'F1 score'])\n",
        "df_scores.sort_values('F1 score', ascending=False)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>F1 score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CamemBERT</td>\n",
              "      <td>0.503813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TF-IDF</td>\n",
              "      <td>0.444092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>0.387657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FastText</td>\n",
              "      <td>0.348117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Model  F1 score\n",
              "3  CamemBERT  0.503813\n",
              "0     TF-IDF  0.444092\n",
              "2    Doc2Vec  0.387657\n",
              "1   FastText  0.348117"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k07PcLHf2JZC",
        "colab_type": "text"
      },
      "source": [
        "We find that CamemBERT has the highest F1 score. In order to make a qualitative evaluation of this model, we build the confusion matrix based on the predictions of CamemBERT on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR93044f2zXx",
        "colab_type": "text"
      },
      "source": [
        "### Qualitative evaluation: confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5A1NnxH2iei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_conf_matrix_df(y_true, y_pred):\n",
        "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
        "    conf_matrix = pd.DataFrame(conf_matrix, columns=list(le.classes_), index=list(le.classes_))\n",
        "    \n",
        "    row_percentages = []\n",
        "    for i in range(0,10):\n",
        "        perc = round(conf_matrix.iloc[i,i]/sum(conf_matrix.iloc[0:10,i]), 3)\n",
        "        row_percentages.append(perc)\n",
        "    \n",
        "    row_percentages = pd.DataFrame([row_percentages], columns=list(le.classes_))\n",
        "    \n",
        "    col_percentages = []\n",
        "    for i in range(0,10):\n",
        "        perc = round(conf_matrix.iloc[i,i]/sum(conf_matrix.iloc[i,0:10]), 3)\n",
        "        col_percentages.append(perc)\n",
        "    col_percentages.append(None)\n",
        "    \n",
        "    conf_matrix = conf_matrix.append(row_percentages)\n",
        "    conf_matrix = conf_matrix.rename(index={0: 'PRECISION'})\n",
        "    conf_matrix['RECALL'] = col_percentages\n",
        "\n",
        "    return(conf_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjEn9dSw3ww3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conf_matrix_BERT = get_conf_matrix_df(y_test, y_test_pred_camembert)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWROz_Hg3-qO",
        "colab_type": "code",
        "outputId": "ff64f1c8-1d5f-4cda-ef53-b299112a0d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "conf_matrix_BERT"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Balzac</th>\n",
              "      <th>Daudet</th>\n",
              "      <th>Dumas</th>\n",
              "      <th>Flaubert</th>\n",
              "      <th>Hugo</th>\n",
              "      <th>Maupassant</th>\n",
              "      <th>Stendhal</th>\n",
              "      <th>Verne</th>\n",
              "      <th>Vigny</th>\n",
              "      <th>Zola</th>\n",
              "      <th>RECALL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Balzac</th>\n",
              "      <td>74.000</td>\n",
              "      <td>20.000</td>\n",
              "      <td>52.000</td>\n",
              "      <td>17.000</td>\n",
              "      <td>30.000</td>\n",
              "      <td>5.000</td>\n",
              "      <td>352.000</td>\n",
              "      <td>489.00</td>\n",
              "      <td>9.000</td>\n",
              "      <td>35.000</td>\n",
              "      <td>0.068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daudet</th>\n",
              "      <td>5.000</td>\n",
              "      <td>97.000</td>\n",
              "      <td>52.000</td>\n",
              "      <td>64.000</td>\n",
              "      <td>22.000</td>\n",
              "      <td>45.000</td>\n",
              "      <td>9.000</td>\n",
              "      <td>22.00</td>\n",
              "      <td>2.000</td>\n",
              "      <td>24.000</td>\n",
              "      <td>0.284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dumas</th>\n",
              "      <td>34.000</td>\n",
              "      <td>6.000</td>\n",
              "      <td>2091.000</td>\n",
              "      <td>19.000</td>\n",
              "      <td>49.000</td>\n",
              "      <td>53.000</td>\n",
              "      <td>33.000</td>\n",
              "      <td>21.00</td>\n",
              "      <td>4.000</td>\n",
              "      <td>10.000</td>\n",
              "      <td>0.901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flaubert</th>\n",
              "      <td>1.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>20.000</td>\n",
              "      <td>464.000</td>\n",
              "      <td>14.000</td>\n",
              "      <td>48.000</td>\n",
              "      <td>11.000</td>\n",
              "      <td>7.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>38.000</td>\n",
              "      <td>0.763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hugo</th>\n",
              "      <td>10.000</td>\n",
              "      <td>31.000</td>\n",
              "      <td>79.000</td>\n",
              "      <td>48.000</td>\n",
              "      <td>202.000</td>\n",
              "      <td>23.000</td>\n",
              "      <td>1072.000</td>\n",
              "      <td>9.00</td>\n",
              "      <td>62.000</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Maupassant</th>\n",
              "      <td>16.000</td>\n",
              "      <td>42.000</td>\n",
              "      <td>34.000</td>\n",
              "      <td>20.000</td>\n",
              "      <td>22.000</td>\n",
              "      <td>138.000</td>\n",
              "      <td>5.000</td>\n",
              "      <td>22.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>18.000</td>\n",
              "      <td>0.434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stendhal</th>\n",
              "      <td>1.000</td>\n",
              "      <td>18.000</td>\n",
              "      <td>62.000</td>\n",
              "      <td>6.000</td>\n",
              "      <td>13.000</td>\n",
              "      <td>6.000</td>\n",
              "      <td>530.000</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>16.000</td>\n",
              "      <td>0.809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Verne</th>\n",
              "      <td>2.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>148.000</td>\n",
              "      <td>12.000</td>\n",
              "      <td>29.000</td>\n",
              "      <td>6.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>197.00</td>\n",
              "      <td>1.000</td>\n",
              "      <td>10.000</td>\n",
              "      <td>0.479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vigny</th>\n",
              "      <td>16.000</td>\n",
              "      <td>95.000</td>\n",
              "      <td>56.000</td>\n",
              "      <td>6.000</td>\n",
              "      <td>27.000</td>\n",
              "      <td>13.000</td>\n",
              "      <td>23.000</td>\n",
              "      <td>15.00</td>\n",
              "      <td>16.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Zola</th>\n",
              "      <td>61.000</td>\n",
              "      <td>24.000</td>\n",
              "      <td>145.000</td>\n",
              "      <td>79.000</td>\n",
              "      <td>8.000</td>\n",
              "      <td>89.000</td>\n",
              "      <td>49.000</td>\n",
              "      <td>38.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>485.000</td>\n",
              "      <td>0.496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRECISION</th>\n",
              "      <td>0.336</td>\n",
              "      <td>0.284</td>\n",
              "      <td>0.763</td>\n",
              "      <td>0.631</td>\n",
              "      <td>0.486</td>\n",
              "      <td>0.324</td>\n",
              "      <td>0.254</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.165</td>\n",
              "      <td>0.757</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Balzac  Daudet     Dumas  Flaubert  ...   Verne   Vigny     Zola  RECALL\n",
              "Balzac      74.000  20.000    52.000    17.000  ...  489.00   9.000   35.000   0.068\n",
              "Daudet       5.000  97.000    52.000    64.000  ...   22.00   2.000   24.000   0.284\n",
              "Dumas       34.000   6.000  2091.000    19.000  ...   21.00   4.000   10.000   0.901\n",
              "Flaubert     1.000   4.000    20.000   464.000  ...    7.00   1.000   38.000   0.763\n",
              "Hugo        10.000  31.000    79.000    48.000  ...    9.00  62.000    5.000   0.131\n",
              "Maupassant  16.000  42.000    34.000    20.000  ...   22.00   1.000   18.000   0.434\n",
              "Stendhal     1.000  18.000    62.000     6.000  ...    2.00   1.000   16.000   0.809\n",
              "Verne        2.000   4.000   148.000    12.000  ...  197.00   1.000   10.000   0.479\n",
              "Vigny       16.000  95.000    56.000     6.000  ...   15.00  16.000    0.000   0.060\n",
              "Zola        61.000  24.000   145.000    79.000  ...   38.00   0.000  485.000   0.496\n",
              "PRECISION    0.336   0.284     0.763     0.631  ...    0.24   0.165    0.757     NaN\n",
              "\n",
              "[11 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    }
  ]
}